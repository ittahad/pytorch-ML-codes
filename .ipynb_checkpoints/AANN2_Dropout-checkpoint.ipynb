{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FeFfkAp7HGSl",
    "outputId": "afd7dcf2-b23f-4898-c7e6-075020b567ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f84401e3670>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "tabu1 = []\n",
    "tabu2 = []\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size_train = 512\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kN22sGD4O1Re"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.FashionMNIST('./data', train=True, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.FashionMNIST('./data', train=False, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# print(train_loader)\n",
    "# examples = enumerate(train_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples)\n",
    "# print(example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z0Q1QfHSHGS6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.CIFAR100('./data', train=True, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.CIFAR100('./data', train=False, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# print(train_loader)\n",
    "# examples = enumerate(train_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples)\n",
    "# print(example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 870
    },
    "colab_type": "code",
    "id": "dm1RiT4cHGTK",
    "outputId": "deb79313-c1bf-4dcb-be29-5b0fe34a9453"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f84593e8f60>\n",
      "torch.Size([512, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR10('./cifar10_dataset', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.49137255, 0.48235294, 0.44666667), (0.24705882, 0.24352941, 0.26156863))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.CIFAR10('./cifar10_dataset', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.49137255, 0.48235294, 0.44666667), (0.24705882, 0.24352941, 0.26156863))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "print(train_loader)\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwEvmG00HGTY"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.SVHN('./data', split='train', download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.SVHN('./data', split='test', download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                torchvision.transforms.Normalize(\n",
    "#                                  (0.1307,), (0.3081,))\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# print(train_loader)\n",
    "# examples = enumerate(train_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples)\n",
    "# print(example_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eV5zVHMxHGTj"
   },
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.MNIST('./data', train=True, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#   torchvision.datasets.MNIST('./data', train=False, download=True,\n",
    "#                              transform=torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                              ])),\n",
    "#   batch_size=batch_size_test, shuffle=True)\n",
    "\n",
    "# print(train_loader)\n",
    "# examples = enumerate(train_loader)\n",
    "# batch_idx, (example_data, example_targets) = next(examples)\n",
    "# print(example_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YqDIPMrUaqyc"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_loader.dataset))\n",
    "test_size = len(train_loader.dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(train_loader.dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, \n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xudGGOWHaqyk",
    "outputId": "1395b093-cded-4841-bf2f-01454712e386"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0020, -0.0026, -0.0014])\n",
      "tensor([0.8192, 0.8192, 0.7686])\n"
     ]
    }
   ],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0.\n",
    "for data, _ in train_loader:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "train_loader.dataset.transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 mean, std)\n",
    "                             ])\n",
    "test_loader.dataset.transform = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 mean, std)\n",
    "                             ])\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dl7nDBdAHGTw"
   },
   "outputs": [],
   "source": [
    "def initMatrix(size, append_with):\n",
    "    ary = []\n",
    "    for i in range(0, size):\n",
    "        ary.append(append_with)\n",
    "    return ary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4oV8a1eVVSr"
   },
   "outputs": [],
   "source": [
    "tabu1 = initMatrix(4096, 1)\n",
    "tabu2 = initMatrix(4096, 1)\n",
    "\n",
    "layer1_dropout = 0.2\n",
    "layer2_dropout = 0.2\n",
    "\n",
    "layer1_diff = 1.0-layer1_dropout\n",
    "layer2_diff = 1.0-layer2_dropout\n",
    "\n",
    "#tabu3 = initMatrix(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrjISTO9HGT6"
   },
   "outputs": [],
   "source": [
    "from torch.nn.modules import Module\n",
    "from torch.nn import functional as F\n",
    "from torch._jit_internal import weak_module, weak_script_method\n",
    "\n",
    "class Dropout(Module):\n",
    "    def __init__(self, p=0.5, inplace=False):\n",
    "        super(Dropout, self).__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\"dropout probability has to be between 0 and 1, \"\n",
    "                             \"but got {}\".format(p))\n",
    "        self.p = p\n",
    "        self.inplace = inplace\n",
    "        print(\"Updated Dropout: \" + str(p))\n",
    "\n",
    "    def forward(self, input):\n",
    "        varTemp = F.dropout(input, self.p, self.training, self.inplace)\n",
    "        return varTemp\n",
    "\n",
    "    def __repr__(self):\n",
    "        inplace_str = ', inplace' if self.inplace else ''\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "            + 'p=' + str(self.p) \\\n",
    "            + inplace_str + ')'\n",
    "      \n",
    "class MyLinear(torch.nn.Linear):\n",
    "    def __init__(self, in_feats, out_feats, drop_p, t, bias=True):\n",
    "        super(MyLinear, self).__init__(in_feats, out_feats, bias=bias)\n",
    "        self.masker = Dropout(p=drop_p)\n",
    "        self.tabu = t\n",
    "        self.firstItr = True\n",
    "        self.historial_tabu_count = initMatrix(4096, 0)\n",
    "\n",
    "    def forward(self, input):\n",
    "       \n",
    "        print(\"Input\")\n",
    "        print(input)\n",
    "        print(\"Self weight\")\n",
    "        print(self.weight)\n",
    "        print(\"Masked weight\")\n",
    "        masked_weight = self.masker(self.weight)\n",
    "        print(masked_weight)\n",
    "        output = F.linear(input, masked_weight, self.bias)\n",
    "        print(\"Output\")\n",
    "        print(output)\n",
    "       \n",
    "        '''\n",
    "        if self.firstItr == True:\n",
    "            \n",
    "            self.firstItr = False\n",
    "            for i in range(0, len(output[0])):\n",
    "                if output[0][i] < 0:\n",
    "                    # Neuron will be dropped\n",
    "                    self.tabu[i] = 0\n",
    "        else:\n",
    "            \n",
    "            temp_tabu = initMatrix(len(output[0]), 1)\n",
    "            \n",
    "            for i in range(0, len(output[0])):\n",
    "                if output[0][i] < 0:\n",
    "                    # Neuron will be dropped\n",
    "                    temp_tabu[i] = 0\n",
    "\n",
    "            for i in range(0, len(output[0])):\n",
    "                if (self.tabu[i] == 0 and temp_tabu[i] == 0):\n",
    "                    # Neuron will be dropped\n",
    "                    self.historial_tabu_count[i] = self.historial_tabu_count[i] + 1\n",
    "                    \n",
    "                    if self.historial_tabu_count[i] > 2:\n",
    "                        self.tabu[i] = 1\n",
    "                        output[0][i] = input[0][i]\n",
    "                        self.historial_tabu_count[i] = 0\n",
    "                    else:\n",
    "                        self.tabu[i] = temp_tabu[i]\n",
    "                        '''\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def updateCurrentDropout(self, m):\n",
    "        tempM = '{:.2f}'.format(m)\n",
    "        self.masker = Dropout(p=float(tempM))  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ei-XUUvmHGUO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "       \n",
    "        # define the layers and their sizes, turn off bias\n",
    "        \n",
    "        self.fc1 = nn.Linear(3072, 4096)\n",
    "       \n",
    "        self.aD1 = MyLinear(4096, 4096, layer1_dropout, tabu1) #nn.Dropout(0.5) # # #      \n",
    "        \n",
    "        #self.d2 = nn.Dropout(0.5)\n",
    "        self.aD2 = MyLinear(4096, 4096, layer2_dropout, tabu2) \n",
    "        #self.fc2 = nn.Linear(1024, 1024)\n",
    "        #self.d2 = Dropout(0.5) \n",
    "        #self.fc3 = nn.Linear(1024, 1024)\n",
    "        \n",
    "        #For CIFAR-10\n",
    "        #self.d3 = Dropout(0.3) \n",
    "        #self.fc3_1 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.fc4 = nn.Linear(4096, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3072)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = self.aD1(x)\n",
    "        #x = F.relu(self.dT(x))\n",
    "        x = self.aD2(x)\n",
    "        \n",
    "        #x = F.relu(self.d2(x))\n",
    "        #x = F.relu(self.fc3(x))\n",
    "        \n",
    "        # for CIFAR-10\n",
    "        #x = F.relu(self.d3(x))\n",
    "        #x = F.relu(self.fc3_1(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x)\n",
    "      \n",
    "    def updateDropout(self, m):\n",
    "        self.aD1.updateCurrentDropout(m)\n",
    "        #self.aD2.updateCurrentDropout(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9jp8qjX7HGUa",
    "outputId": "116b01e2-6de4-4627-a563-ba33b09af78b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dropout: 0.2\n",
      "Updated Dropout: 0.2\n"
     ]
    }
   ],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JbkKpxVLaqzS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgE1I92yHGVA"
   },
   "outputs": [],
   "source": [
    "avg_train_loss = []\n",
    "avg_train_counter = []\n",
    "avg_test_loss = []\n",
    "avg_test_counter = []\n",
    "test_accuracy_list = []\n",
    "\n",
    "test_losses = []\n",
    "test_counter = []\n",
    "\n",
    "epoch_number = 0\n",
    "train_avg_loss = 0\n",
    "test_avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pvp82UTxn0lh"
   },
   "outputs": [],
   "source": [
    "# 0 means negative\n",
    "# 1 means positive\n",
    "loss_type = 0\n",
    "previous_loss = 100.0\n",
    "sign_manipulator = 1\n",
    "\n",
    "pos_inc = 0\n",
    "neg_inc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGOcLvQ2HGVG"
   },
   "outputs": [],
   "source": [
    "def train(epoch, layer1_dropout):\n",
    "    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    \n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            #torch.save(network.state_dict(), './results/cifar10_with_adaptive_model.pth')\n",
    "            #torch.save(optimizer.state_dict(), './results/cifar10_with_adaptive_optimizer.pth')\n",
    "            #test(epoch, False)\n",
    "            \n",
    "    sum = 0.0\n",
    "    for loss in train_losses:\n",
    "        sum = sum + loss\n",
    "    \n",
    "    current_loss = sum / len(train_losses)\n",
    "    \n",
    "    avg_train_loss.append(current_loss)\n",
    "    network.updateDropout(layer1_dropout)\n",
    "    return current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qwqm3AuCHGVM"
   },
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "        #iterator = iter(test_loader)\n",
    "        #data, target= iterator.next() \n",
    "        \n",
    "            examples = enumerate(val_loader)\n",
    "            batch_idx, (example_data, example_targets) = next(examples)  \n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "\n",
    "    test_loss /= len(val_loader.dataset)\n",
    "    avg_test_loss.append(test_loss)\n",
    "    test_counter.append((batch_idx*64) + ((epoch-1)*len(val_loader.dataset)))\n",
    "    test_accuracy_list.append(100. * correct / len(val_loader.dataset))\n",
    "    \n",
    "    print('Test set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return test_loss\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6970
    },
    "colab_type": "code",
    "id": "77ZTDVwnHGVS",
    "outputId": "388db92b-ed9f-4ce8-f688-d014d86bab30",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[ 0.1057,  0.0931,  0.7012,  ...,  0.3540,  0.0557,  0.1668],\n",
      "        [-0.2883, -0.4094,  0.3052,  ..., -0.0082,  0.8515, -0.9482],\n",
      "        [ 0.2915,  0.6064,  0.3521,  ...,  0.3888,  0.0293,  0.1186],\n",
      "        ...,\n",
      "        [-0.5698,  0.3141, -0.8454,  ...,  0.2295,  0.4759,  0.2426],\n",
      "        [ 0.9195, -0.5861, -0.4176,  ..., -0.1610, -0.8755, -0.2498],\n",
      "        [ 0.2923,  0.0560,  0.6185,  ..., -0.4598, -0.1661,  0.2363]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0031,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0115,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0000, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0000,  0.0074, -0.0086,  ...,  0.0000, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0000,  ...,  0.0016,  0.0039,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0037,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.1891,  0.3267, -0.1643,  ...,  0.1665, -0.1821,  0.0641],\n",
      "        [ 0.3867, -0.5378,  0.4022,  ..., -0.1092, -0.6743,  0.5844],\n",
      "        [-0.2488, -0.3040, -0.0524,  ...,  0.5375, -0.3193, -0.1214],\n",
      "        ...,\n",
      "        [-0.2916, -0.2584, -0.3849,  ...,  0.2077, -0.5561, -0.2967],\n",
      "        [-0.0043, -0.2378,  0.3028,  ..., -0.0109,  0.5078, -0.2282],\n",
      "        [-0.2481, -0.0824,  0.0383,  ...,  0.0222, -0.0870,  0.2584]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.1891,  0.3267, -0.1643,  ...,  0.1665, -0.1821,  0.0641],\n",
      "        [ 0.3867, -0.5378,  0.4022,  ..., -0.1092, -0.6743,  0.5844],\n",
      "        [-0.2488, -0.3040, -0.0524,  ...,  0.5375, -0.3193, -0.1214],\n",
      "        ...,\n",
      "        [-0.2916, -0.2584, -0.3849,  ...,  0.2077, -0.5561, -0.2967],\n",
      "        [-0.0043, -0.2378,  0.3028,  ..., -0.0109,  0.5078, -0.2282],\n",
      "        [-0.2481, -0.0824,  0.0383,  ...,  0.0222, -0.0870,  0.2584]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0147, -0.0005,  0.0074,  ..., -0.0102, -0.0144, -0.0150],\n",
      "        [-0.0074,  0.0107,  0.0067,  ..., -0.0132, -0.0136, -0.0093],\n",
      "        [-0.0082, -0.0140,  0.0088,  ..., -0.0039, -0.0100,  0.0127],\n",
      "        ...,\n",
      "        [ 0.0134,  0.0039,  0.0021,  ..., -0.0118,  0.0074, -0.0040],\n",
      "        [ 0.0001,  0.0110, -0.0138,  ..., -0.0144, -0.0074,  0.0094],\n",
      "        [-0.0099, -0.0055,  0.0036,  ..., -0.0060, -0.0036, -0.0094]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0000, -0.0006,  0.0092,  ..., -0.0127, -0.0180, -0.0188],\n",
      "        [-0.0092,  0.0000,  0.0083,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0000,  0.0110,  ..., -0.0000, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0049,  0.0027,  ..., -0.0147,  0.0092, -0.0050],\n",
      "        [ 0.0001,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0117],\n",
      "        [-0.0124, -0.0069,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.1810,  0.1176, -0.0131,  ..., -0.2324, -0.2737,  0.0360],\n",
      "        [ 0.5137, -0.2362, -0.1913,  ...,  0.3887, -0.2057,  0.0537],\n",
      "        [-0.0192,  0.1147, -0.2541,  ..., -0.3137, -0.0480,  0.1703],\n",
      "        ...,\n",
      "        [-0.1465, -0.0885,  0.0932,  ..., -0.1312, -0.3591, -0.2476],\n",
      "        [-0.0757,  0.2140,  0.0191,  ..., -0.0408,  0.2376,  0.0675],\n",
      "        [ 0.0049,  0.0471,  0.1058,  ...,  0.0025, -0.0966,  0.0569]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akash/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/40000 (0%)]\tLoss: 2.306668\n",
      "Input\n",
      "tensor([[ 0.2596, -0.2573,  0.0059,  ...,  1.0868, -0.3748, -0.7371],\n",
      "        [ 0.5700, -0.4022,  0.4591,  ...,  0.6000, -0.7769,  0.4060],\n",
      "        [-0.1442,  0.3653, -0.1330,  ...,  0.1469,  0.6947, -0.8692],\n",
      "        ...,\n",
      "        [-0.1265, -0.8040, -0.0045,  ..., -0.0777, -0.1155,  0.3941],\n",
      "        [-0.0329,  0.3894,  0.3413,  ..., -0.1905, -0.5137,  0.0849],\n",
      "        [-0.2723, -0.1457,  0.2010,  ..., -0.4564, -0.5041, -0.4509]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0031,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0150, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0115,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0000,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0000, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0000, -0.0120,  0.0000],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0000,  ...,  0.0000, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0000,  0.0000,  0.0130],\n",
      "        [-0.0000,  0.0047,  0.0037,  ..., -0.0000, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 4.1796e-01, -2.0341e-01, -4.3975e-01,  ...,  1.9679e-01,\n",
      "          3.8920e-01, -1.4827e+00],\n",
      "        [-2.0811e-01, -6.3272e-01,  4.4119e-01,  ..., -3.5269e-01,\n",
      "          2.7252e-01,  1.0616e-01],\n",
      "        [ 3.0219e-01, -4.2183e-01,  4.6229e-02,  ..., -4.0844e-02,\n",
      "          1.0672e-01, -1.9333e-01],\n",
      "        ...,\n",
      "        [-7.4592e-01,  4.2575e-01, -4.7207e-01,  ...,  2.4084e-01,\n",
      "          6.8102e-01,  2.6364e-01],\n",
      "        [-8.3685e-02, -4.3251e-01, -5.5522e-01,  ...,  3.2603e-01,\n",
      "          1.8968e-01, -5.4234e-01],\n",
      "        [ 1.3300e-03, -1.8597e-01,  8.3287e-02,  ...,  4.4109e-01,\n",
      "          1.4031e-01, -1.1285e+00]], grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 4.1796e-01, -2.0341e-01, -4.3975e-01,  ...,  1.9679e-01,\n",
      "          3.8920e-01, -1.4827e+00],\n",
      "        [-2.0811e-01, -6.3272e-01,  4.4119e-01,  ..., -3.5269e-01,\n",
      "          2.7252e-01,  1.0616e-01],\n",
      "        [ 3.0219e-01, -4.2183e-01,  4.6229e-02,  ..., -4.0844e-02,\n",
      "          1.0672e-01, -1.9333e-01],\n",
      "        ...,\n",
      "        [-7.4592e-01,  4.2575e-01, -4.7207e-01,  ...,  2.4084e-01,\n",
      "          6.8102e-01,  2.6364e-01],\n",
      "        [-8.3685e-02, -4.3251e-01, -5.5522e-01,  ...,  3.2603e-01,\n",
      "          1.8968e-01, -5.4234e-01],\n",
      "        [ 1.3300e-03, -1.8597e-01,  8.3287e-02,  ...,  4.4109e-01,\n",
      "          1.4031e-01, -1.1285e+00]], grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4725e-02, -5.0527e-04,  7.3719e-03,  ..., -1.0199e-02,\n",
      "         -1.4372e-02, -1.5044e-02],\n",
      "        [-7.3900e-03,  1.0705e-02,  6.6755e-03,  ..., -1.3235e-02,\n",
      "         -1.3626e-02, -9.2873e-03],\n",
      "        [-8.2317e-03, -1.4039e-02,  8.8260e-03,  ..., -3.9074e-03,\n",
      "         -1.0015e-02,  1.2668e-02],\n",
      "        ...,\n",
      "        [ 1.3383e-02,  3.8836e-03,  2.1391e-03,  ..., -1.1802e-02,\n",
      "          7.3943e-03, -4.0071e-03],\n",
      "        [ 9.4846e-05,  1.0986e-02, -1.3830e-02,  ..., -1.4397e-02,\n",
      "         -7.4347e-03,  9.3793e-03],\n",
      "        [-9.9270e-03, -5.5366e-03,  3.5746e-03,  ..., -6.0000e-03,\n",
      "         -3.5820e-03, -9.4184e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0000, -0.0006,  0.0092,  ..., -0.0127, -0.0180, -0.0188],\n",
      "        [-0.0092,  0.0000,  0.0083,  ..., -0.0165, -0.0000, -0.0116],\n",
      "        [-0.0103, -0.0175,  0.0110,  ..., -0.0000, -0.0125,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0049,  0.0027,  ..., -0.0000,  0.0092, -0.0000],\n",
      "        [ 0.0001,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0117],\n",
      "        [-0.0000, -0.0069,  0.0000,  ..., -0.0000, -0.0000, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-5.0854e-01, -2.4488e-01, -1.0427e-01,  ..., -1.9438e-01,\n",
      "          2.0077e-01, -2.5188e-01],\n",
      "        [ 6.0182e-01, -1.0311e-01,  1.7337e-01,  ...,  1.9377e-02,\n",
      "         -1.2021e-01,  8.7940e-02],\n",
      "        [-7.4326e-01,  1.2365e-01,  6.9330e-04,  ...,  2.3106e-02,\n",
      "          1.0870e-01, -3.5324e-01],\n",
      "        ...,\n",
      "        [ 2.5246e-01, -2.3377e-01, -2.9220e-01,  ...,  1.5566e-01,\n",
      "         -2.0354e-01,  3.2314e-01],\n",
      "        [-5.8887e-01,  2.5384e-01, -4.7508e-02,  ..., -1.1086e-01,\n",
      "         -6.9216e-02, -1.3012e-01],\n",
      "        [-2.5762e-01,  7.1284e-02,  1.0603e-01,  ..., -2.7510e-01,\n",
      "          1.7663e-01, -2.9058e-01]], grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.6778,  0.4333, -0.3889,  ...,  1.3872, -0.5330,  0.0883],\n",
      "        [ 0.4178, -0.5949,  0.1534,  ..., -0.4055, -0.1476, -0.3774],\n",
      "        [-0.1172,  0.9673, -0.9631,  ..., -0.0482, -0.5321, -0.5376],\n",
      "        ...,\n",
      "        [-0.1721, -0.0034, -0.5754,  ...,  0.2627,  0.5251, -0.2728],\n",
      "        [-0.1134, -0.2804,  0.3096,  ...,  1.4862, -1.0793, -0.5164],\n",
      "        [-0.0151,  0.5591, -0.3035,  ..., -0.4141, -1.2082, -1.1163]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0031,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0115,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0000, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0000, -0.0086,  ...,  0.0067, -0.0180,  0.0000],\n",
      "        [-0.0188, -0.0165,  0.0000,  ...,  0.0016,  0.0000,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.8719, -0.5751, -0.7847,  ..., -0.2324,  0.0434,  0.0179],\n",
      "        [ 0.4184,  0.6014,  0.5756,  ..., -0.4705,  0.1737, -0.0905],\n",
      "        [-0.7623, -0.3860, -0.3986,  ...,  0.9744, -0.1039, -0.3715],\n",
      "        ...,\n",
      "        [-0.8886,  0.4335,  0.0448,  ..., -0.2322, -0.1586, -0.1895],\n",
      "        [ 0.3033, -0.3345,  0.4650,  ..., -0.2765,  0.3859, -0.3079],\n",
      "        [-0.5176, -1.3617, -0.0351,  ...,  0.5833, -0.6455, -0.4141]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.8719, -0.5751, -0.7847,  ..., -0.2324,  0.0434,  0.0179],\n",
      "        [ 0.4184,  0.6014,  0.5756,  ..., -0.4705,  0.1737, -0.0905],\n",
      "        [-0.7623, -0.3860, -0.3986,  ...,  0.9744, -0.1039, -0.3715],\n",
      "        ...,\n",
      "        [-0.8886,  0.4335,  0.0448,  ..., -0.2322, -0.1586, -0.1895],\n",
      "        [ 0.3033, -0.3345,  0.4650,  ..., -0.2765,  0.3859, -0.3079],\n",
      "        [-0.5176, -1.3617, -0.0351,  ...,  0.5833, -0.6455, -0.4141]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4725e-02, -5.0367e-04,  7.3798e-03,  ..., -1.0198e-02,\n",
      "         -1.4372e-02, -1.5050e-02],\n",
      "        [-7.3873e-03,  1.0705e-02,  6.6830e-03,  ..., -1.3233e-02,\n",
      "         -1.3626e-02, -9.2914e-03],\n",
      "        [-8.2288e-03, -1.4040e-02,  8.8286e-03,  ..., -3.9074e-03,\n",
      "         -1.0016e-02,  1.2668e-02],\n",
      "        ...,\n",
      "        [ 1.3382e-02,  3.8825e-03,  2.1391e-03,  ..., -1.1802e-02,\n",
      "          7.3928e-03, -4.0071e-03],\n",
      "        [ 8.8309e-05,  1.0983e-02, -1.3845e-02,  ..., -1.4396e-02,\n",
      "         -7.4348e-03,  9.3826e-03],\n",
      "        [-9.9270e-03, -5.5317e-03,  3.5746e-03,  ..., -6.0000e-03,\n",
      "         -3.5820e-03, -9.4190e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0184, -0.0006,  0.0092,  ..., -0.0127, -0.0180, -0.0188],\n",
      "        [-0.0092,  0.0134,  0.0084,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0000,  0.0110,  ..., -0.0049, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0049,  0.0027,  ..., -0.0148,  0.0092, -0.0000],\n",
      "        [ 0.0001,  0.0137, -0.0173,  ..., -0.0180, -0.0000,  0.0000],\n",
      "        [-0.0124, -0.0069,  0.0045,  ..., -0.0075, -0.0000, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.6941, -0.3804,  0.2265,  ..., -0.2670, -0.3883,  0.2476],\n",
      "        [ 0.9333,  0.2956, -0.3583,  ...,  0.3415,  0.4931,  0.3378],\n",
      "        [-1.2447,  0.0171,  0.3867,  ..., -0.2413, -0.3770, -0.7955],\n",
      "        ...,\n",
      "        [-0.4543, -0.0313,  0.1726,  ..., -0.2786, -0.0982,  0.1292],\n",
      "        [ 0.3767,  0.0268,  0.0562,  ...,  0.3443,  0.3358,  0.3203],\n",
      "        [-1.2948, -0.5501,  0.4811,  ...,  0.1036, -0.1909, -0.7196]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[ 4.6448e-01, -4.8871e-01,  8.6093e-01,  ...,  1.9548e-01,\n",
      "         -6.1437e-01,  3.6905e-01],\n",
      "        [ 4.1648e-01,  5.8141e-01,  6.8713e-04,  ..., -2.5936e-01,\n",
      "         -5.7949e-01, -1.3408e-01],\n",
      "        [ 2.6245e-01, -2.1804e-02,  1.4735e-01,  ..., -6.5276e-01,\n",
      "          4.9773e-01,  1.0905e-01],\n",
      "        ...,\n",
      "        [ 2.3792e-01,  4.3651e-02,  1.1889e-01,  ..., -5.0668e-01,\n",
      "          1.3968e-01,  1.8666e-01],\n",
      "        [-5.2604e-02,  9.0475e-01,  4.1157e-01,  ...,  4.9885e-01,\n",
      "         -4.0199e-01,  5.2860e-01],\n",
      "        [ 1.3658e-01,  7.2609e-01, -7.3980e-01,  ...,  3.3044e-01,\n",
      "          7.9758e-01, -4.1884e-02]], grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0031,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0149,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0000, -0.0083,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0000,  0.0017,  ...,  0.0016,  0.0039,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.5025,  0.0816, -0.1478,  ..., -0.0051, -0.1785,  0.6825],\n",
      "        [-0.5215,  0.3318,  0.1394,  ...,  0.5137, -0.1394, -0.0157],\n",
      "        [-0.6047,  0.2601,  0.3907,  ..., -0.7160,  0.2897,  0.2865],\n",
      "        ...,\n",
      "        [ 0.2654, -0.0733,  0.2006,  ..., -0.8795, -0.0744,  0.2203],\n",
      "        [-0.4312, -0.0213, -0.1888,  ...,  0.6946,  0.1252,  0.0915],\n",
      "        [-1.0368,  0.0719, -0.0231,  ...,  0.4294,  0.0130,  0.2309]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.5025,  0.0816, -0.1478,  ..., -0.0051, -0.1785,  0.6825],\n",
      "        [-0.5215,  0.3318,  0.1394,  ...,  0.5137, -0.1394, -0.0157],\n",
      "        [-0.6047,  0.2601,  0.3907,  ..., -0.7160,  0.2897,  0.2865],\n",
      "        ...,\n",
      "        [ 0.2654, -0.0733,  0.2006,  ..., -0.8795, -0.0744,  0.2203],\n",
      "        [-0.4312, -0.0213, -0.1888,  ...,  0.6946,  0.1252,  0.0915],\n",
      "        [-1.0368,  0.0719, -0.0231,  ...,  0.4294,  0.0130,  0.2309]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4738e-02, -5.0542e-04,  7.3861e-03,  ..., -1.0196e-02,\n",
      "         -1.4373e-02, -1.5052e-02],\n",
      "        [-7.3782e-03,  1.0704e-02,  6.6900e-03,  ..., -1.3231e-02,\n",
      "         -1.3629e-02, -9.2956e-03],\n",
      "        [-8.2297e-03, -1.4040e-02,  8.8311e-03,  ..., -3.9037e-03,\n",
      "         -1.0020e-02,  1.2666e-02],\n",
      "        ...,\n",
      "        [ 1.3386e-02,  3.8854e-03,  2.1398e-03,  ..., -1.1804e-02,\n",
      "          7.3933e-03, -4.0071e-03],\n",
      "        [ 7.3797e-05,  1.0981e-02, -1.3856e-02,  ..., -1.4395e-02,\n",
      "         -7.4348e-03,  9.3826e-03],\n",
      "        [-9.9173e-03, -5.5312e-03,  3.5784e-03,  ..., -6.0004e-03,\n",
      "         -3.5820e-03, -9.4173e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8422e-02, -6.3178e-04,  9.2326e-03,  ..., -1.2745e-02,\n",
      "         -1.7966e-02, -1.8815e-02],\n",
      "        [-9.2227e-03,  1.3380e-02,  8.3624e-03,  ..., -1.6538e-02,\n",
      "         -1.7036e-02, -1.1619e-02],\n",
      "        [-1.0287e-02, -1.7550e-02,  1.1039e-02,  ..., -4.8796e-03,\n",
      "         -1.2525e-02,  1.5832e-02],\n",
      "        ...,\n",
      "        [ 1.6733e-02,  4.8567e-03,  2.6747e-03,  ..., -1.4755e-02,\n",
      "          9.2416e-03, -5.0089e-03],\n",
      "        [ 9.2246e-05,  1.3726e-02, -1.7320e-02,  ..., -0.0000e+00,\n",
      "         -9.2935e-03,  1.1728e-02],\n",
      "        [-1.2397e-02, -6.9140e-03,  4.4730e-03,  ..., -7.5004e-03,\n",
      "         -4.4775e-03, -1.1772e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.4097, -0.0964,  0.1072,  ...,  0.0382, -0.2683, -0.2335],\n",
      "        [-0.3621,  0.1191,  0.2696,  ...,  0.2678, -0.0084,  0.0074],\n",
      "        [-0.0234,  0.2224,  0.0245,  ...,  0.0457, -0.3525,  0.3163],\n",
      "        ...,\n",
      "        [ 0.2178,  0.1388, -0.0614,  ..., -0.0261,  0.2519, -0.1612],\n",
      "        [ 0.0103, -0.0408,  0.0765,  ..., -0.0441, -0.0542,  0.2734],\n",
      "        [-0.3654, -0.0496, -0.0296,  ..., -0.4810, -0.2362,  0.1363]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.4185, -0.2740, -0.3867,  ...,  1.0037, -0.6060, -0.4337],\n",
      "        [-0.2017, -0.1713,  0.1852,  ..., -0.4673,  0.0263,  0.3243],\n",
      "        [ 0.1890, -0.0768,  0.1364,  ..., -0.1681,  0.0433,  0.1017],\n",
      "        ...,\n",
      "        [ 0.4208,  0.2983, -0.3179,  ...,  0.2721, -0.2388, -0.0438],\n",
      "        [ 0.0303,  0.1659, -0.0193,  ...,  0.4329, -0.0381, -0.0104],\n",
      "        [-0.3692, -0.3112, -0.3866,  ..., -0.0044,  0.2059,  0.2692]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0149,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0000, -0.0194, -0.0179,  ..., -0.0000, -0.0083,  0.0072],\n",
      "        [-0.0167,  0.0000,  0.0000,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0000, -0.0165,  0.0017,  ...,  0.0016,  0.0039,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0000, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 6.4428e-01, -4.6922e-01,  6.7271e-01,  ..., -7.8981e-01,\n",
      "         -7.5276e-02, -4.2901e-01],\n",
      "        [ 3.1051e-01,  5.2943e-01,  1.0929e+00,  ..., -1.0846e-01,\n",
      "         -1.5201e-04, -3.6230e-01],\n",
      "        [ 5.9049e-01,  6.7145e-02,  3.2175e-01,  ..., -1.1400e-01,\n",
      "          3.1388e-02,  1.4923e-01],\n",
      "        ...,\n",
      "        [-8.3831e-02, -1.7009e-01, -4.4665e-01,  ...,  1.1264e-02,\n",
      "         -1.4383e-01, -2.1069e-01],\n",
      "        [-2.4649e-01, -1.7897e-01, -1.1349e-01,  ...,  1.7208e-01,\n",
      "         -4.4423e-02,  1.1504e-01],\n",
      "        [ 5.7573e-02,  8.1363e-01,  9.8210e-01,  ..., -4.3975e-01,\n",
      "         -1.3973e-01,  1.7650e-01]], grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 6.4428e-01, -4.6922e-01,  6.7271e-01,  ..., -7.8981e-01,\n",
      "         -7.5276e-02, -4.2901e-01],\n",
      "        [ 3.1051e-01,  5.2943e-01,  1.0929e+00,  ..., -1.0846e-01,\n",
      "         -1.5201e-04, -3.6230e-01],\n",
      "        [ 5.9049e-01,  6.7145e-02,  3.2175e-01,  ..., -1.1400e-01,\n",
      "          3.1388e-02,  1.4923e-01],\n",
      "        ...,\n",
      "        [-8.3831e-02, -1.7009e-01, -4.4665e-01,  ...,  1.1264e-02,\n",
      "         -1.4383e-01, -2.1069e-01],\n",
      "        [-2.4649e-01, -1.7897e-01, -1.1349e-01,  ...,  1.7208e-01,\n",
      "         -4.4423e-02,  1.1504e-01],\n",
      "        [ 5.7573e-02,  8.1363e-01,  9.8210e-01,  ..., -4.3975e-01,\n",
      "         -1.3973e-01,  1.7650e-01]], grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4744e-02, -5.0017e-04,  7.3918e-03,  ..., -1.0202e-02,\n",
      "         -1.4372e-02, -1.5053e-02],\n",
      "        [-7.3742e-03,  1.0700e-02,  6.6927e-03,  ..., -1.3228e-02,\n",
      "         -1.3631e-02, -9.2977e-03],\n",
      "        [-8.2291e-03, -1.4043e-02,  8.8313e-03,  ..., -3.8986e-03,\n",
      "         -1.0026e-02,  1.2665e-02],\n",
      "        ...,\n",
      "        [ 1.3388e-02,  3.8793e-03,  2.1392e-03,  ..., -1.1801e-02,\n",
      "          7.3929e-03, -4.0073e-03],\n",
      "        [ 6.4936e-05,  1.0980e-02, -1.3859e-02,  ..., -1.4395e-02,\n",
      "         -7.4334e-03,  9.3842e-03],\n",
      "        [-9.9110e-03, -5.5261e-03,  3.5819e-03,  ..., -6.0042e-03,\n",
      "         -3.5820e-03, -9.4169e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8429e-02, -0.0000e+00,  9.2398e-03,  ..., -1.2753e-02,\n",
      "         -1.7966e-02, -0.0000e+00],\n",
      "        [-9.2178e-03,  1.3375e-02,  8.3658e-03,  ..., -1.6535e-02,\n",
      "         -1.7039e-02, -1.1622e-02],\n",
      "        [-1.0286e-02, -0.0000e+00,  1.1039e-02,  ..., -4.8732e-03,\n",
      "         -1.2532e-02,  1.5832e-02],\n",
      "        ...,\n",
      "        [ 1.6735e-02,  4.8491e-03,  2.6740e-03,  ..., -1.4752e-02,\n",
      "          9.2411e-03, -0.0000e+00],\n",
      "        [ 8.1170e-05,  1.3725e-02, -1.7324e-02,  ..., -1.7993e-02,\n",
      "         -9.2917e-03,  1.1730e-02],\n",
      "        [-0.0000e+00, -6.9076e-03,  4.4773e-03,  ..., -7.5053e-03,\n",
      "         -4.4775e-03, -1.1771e-02]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "tensor([[ 0.2259,  0.0421,  0.0463,  ...,  0.1382, -0.0018,  0.1331],\n",
      "        [ 0.2494,  0.1941,  0.0328,  ..., -0.0492,  0.3381,  0.0126],\n",
      "        [ 0.1829, -0.0095,  0.0060,  ..., -0.1850, -0.0808, -0.0419],\n",
      "        ...,\n",
      "        [-0.0980, -0.0818,  0.1785,  ..., -0.0925,  0.1900, -0.1907],\n",
      "        [-0.0828, -0.1246,  0.1052,  ..., -0.1759,  0.0074, -0.0534],\n",
      "        [ 0.5652,  0.3340, -0.0965,  ...,  0.2761, -0.1048,  0.1284]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.1404, -0.8441,  0.3137,  ..., -0.3730, -0.5801,  0.2102],\n",
      "        [-0.2287,  0.7325, -0.7021,  ...,  0.7756,  0.3130, -0.3815],\n",
      "        [ 0.2242, -1.1009, -0.2673,  ..., -0.4789,  0.1660,  0.7511],\n",
      "        ...,\n",
      "        [-0.1681, -0.2319, -0.1027,  ..., -0.1333,  0.2852, -0.5418],\n",
      "        [ 0.3674, -0.1729,  0.0662,  ...,  0.9689,  0.2123,  1.0802],\n",
      "        [ 0.3231, -0.4658,  0.4467,  ...,  0.2115, -0.6656, -0.1065]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0149,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0000, -0.0194, -0.0000,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0167,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0016,  0.0039,  0.0000],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.4947,  0.5810,  0.3507,  ..., -0.5707,  0.0945, -0.0955],\n",
      "        [-0.4939, -0.5058, -0.5656,  ...,  0.3281,  0.1674, -0.3487],\n",
      "        [ 0.1180,  1.5887,  0.4787,  ..., -1.1329, -0.1650,  0.1934],\n",
      "        ...,\n",
      "        [ 0.4115, -0.1478,  0.2448,  ..., -0.1966, -0.2104,  0.1291],\n",
      "        [-0.6718,  0.4518, -0.2284,  ..., -0.3413, -0.4931,  0.3910],\n",
      "        [ 0.7001, -0.0966,  0.3941,  ..., -0.5252, -0.0336, -0.1917]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.4947,  0.5810,  0.3507,  ..., -0.5707,  0.0945, -0.0955],\n",
      "        [-0.4939, -0.5058, -0.5656,  ...,  0.3281,  0.1674, -0.3487],\n",
      "        [ 0.1180,  1.5887,  0.4787,  ..., -1.1329, -0.1650,  0.1934],\n",
      "        ...,\n",
      "        [ 0.4115, -0.1478,  0.2448,  ..., -0.1966, -0.2104,  0.1291],\n",
      "        [-0.6718,  0.4518, -0.2284,  ..., -0.3413, -0.4931,  0.3910],\n",
      "        [ 0.7001, -0.0966,  0.3941,  ..., -0.5252, -0.0336, -0.1917]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4748e-02, -5.0017e-04,  7.3909e-03,  ..., -1.0202e-02,\n",
      "         -1.4375e-02, -1.5053e-02],\n",
      "        [-7.3731e-03,  1.0698e-02,  6.6936e-03,  ..., -1.3228e-02,\n",
      "         -1.3634e-02, -9.2991e-03],\n",
      "        [-8.2310e-03, -1.4043e-02,  8.8310e-03,  ..., -3.8969e-03,\n",
      "         -1.0031e-02,  1.2662e-02],\n",
      "        ...,\n",
      "        [ 1.3393e-02,  3.8819e-03,  2.1451e-03,  ..., -1.1802e-02,\n",
      "          7.3935e-03, -4.0073e-03],\n",
      "        [ 5.7173e-05,  1.0980e-02, -1.3859e-02,  ..., -1.4395e-02,\n",
      "         -7.4328e-03,  9.3859e-03],\n",
      "        [-9.9110e-03, -5.5239e-03,  3.5839e-03,  ..., -6.0042e-03,\n",
      "         -3.5825e-03, -9.4192e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0184, -0.0006,  0.0092,  ..., -0.0128, -0.0180, -0.0000],\n",
      "        [-0.0092,  0.0134,  0.0084,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0000,  0.0110,  ..., -0.0049, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0049,  0.0027,  ..., -0.0148,  0.0000, -0.0050],\n",
      "        [ 0.0000,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0117],\n",
      "        [-0.0124, -0.0000,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.0476,  0.5326,  0.1761,  ..., -0.1507,  0.2891,  0.3347],\n",
      "        [-0.4624, -0.0371,  0.1363,  ..., -0.0406, -0.1640, -0.0892],\n",
      "        [ 0.5495,  0.4882, -0.3622,  ..., -0.1011,  0.0554,  0.6037],\n",
      "        ...,\n",
      "        [ 0.2589, -0.0303,  0.0614,  ...,  0.6105,  0.0390, -0.0607],\n",
      "        [-0.1970,  0.2953, -0.1372,  ..., -0.2733, -0.1104,  0.2203],\n",
      "        [ 0.2281,  0.3225, -0.0497,  ...,  0.0255, -0.0383,  0.1449]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.2987, -0.7946,  0.0754,  ..., -0.5884,  0.2002,  0.3207],\n",
      "        [ 0.2671,  1.0984, -0.1273,  ..., -0.4824,  0.2585,  0.1049],\n",
      "        [ 0.1630, -0.0471,  0.1551,  ..., -0.3832,  0.0764,  0.3314],\n",
      "        ...,\n",
      "        [-0.8138, -1.1215,  1.3140,  ..., -0.6880, -1.0640,  0.6476],\n",
      "        [ 0.0827, -0.7043,  1.1309,  ..., -0.2958,  0.7180,  0.1898],\n",
      "        [-0.1773,  0.1109,  0.2389,  ...,  0.1156,  0.3082, -0.4647]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0000, -0.0179,  ..., -0.0000, -0.0000,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0000,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0039,  ...,  0.0179, -0.0120,  0.0000],\n",
      "        ...,\n",
      "        [-0.0186,  0.0000, -0.0086,  ...,  0.0000, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0016,  0.0000,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0000,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.5633,  0.6360,  0.7626,  ..., -0.5147,  0.1481,  0.0908],\n",
      "        [-0.5932, -0.3395, -0.5861,  ...,  0.0731,  0.2208,  0.6095],\n",
      "        [ 0.1247,  0.1430,  0.0453,  ...,  0.0413,  0.2580,  0.0951],\n",
      "        ...,\n",
      "        [ 0.1777,  1.4373,  0.4372,  ...,  0.3173,  0.4775,  0.4818],\n",
      "        [ 0.4353,  0.4503,  0.4850,  ...,  0.1060, -0.0099, -0.0655],\n",
      "        [ 0.4570, -0.4799, -0.0221,  ...,  0.4861,  0.0933,  0.1496]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.5633,  0.6360,  0.7626,  ..., -0.5147,  0.1481,  0.0908],\n",
      "        [-0.5932, -0.3395, -0.5861,  ...,  0.0731,  0.2208,  0.6095],\n",
      "        [ 0.1247,  0.1430,  0.0453,  ...,  0.0413,  0.2580,  0.0951],\n",
      "        ...,\n",
      "        [ 0.1777,  1.4373,  0.4372,  ...,  0.3173,  0.4775,  0.4818],\n",
      "        [ 0.4353,  0.4503,  0.4850,  ...,  0.1060, -0.0099, -0.0655],\n",
      "        [ 0.4570, -0.4799, -0.0221,  ...,  0.4861,  0.0933,  0.1496]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4761e-02, -4.9799e-04,  7.3950e-03,  ..., -1.0204e-02,\n",
      "         -1.4376e-02, -1.5053e-02],\n",
      "        [-7.3667e-03,  1.0699e-02,  6.6964e-03,  ..., -1.3225e-02,\n",
      "         -1.3634e-02, -9.2993e-03],\n",
      "        [-8.2266e-03, -1.4043e-02,  8.8342e-03,  ..., -3.8930e-03,\n",
      "         -1.0034e-02,  1.2661e-02],\n",
      "        ...,\n",
      "        [ 1.3393e-02,  3.8795e-03,  2.1463e-03,  ..., -1.1799e-02,\n",
      "          7.3935e-03, -4.0075e-03],\n",
      "        [ 5.7173e-05,  1.0978e-02, -1.3863e-02,  ..., -1.4394e-02,\n",
      "         -7.4317e-03,  9.3864e-03],\n",
      "        [-9.8986e-03, -5.5239e-03,  3.5893e-03,  ..., -6.0076e-03,\n",
      "         -3.5855e-03, -9.4194e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0000e+00, -6.2248e-04,  9.2438e-03,  ..., -1.2754e-02,\n",
      "         -1.7970e-02, -1.8816e-02],\n",
      "        [-9.2084e-03,  1.3374e-02,  8.3705e-03,  ..., -1.6531e-02,\n",
      "         -1.7043e-02, -1.1624e-02],\n",
      "        [-1.0283e-02, -1.7554e-02,  1.1043e-02,  ..., -4.8662e-03,\n",
      "         -1.2543e-02,  1.5826e-02],\n",
      "        ...,\n",
      "        [ 1.6741e-02,  4.8494e-03,  0.0000e+00,  ..., -1.4749e-02,\n",
      "          9.2418e-03, -5.0093e-03],\n",
      "        [ 7.1467e-05,  1.3722e-02, -1.7329e-02,  ..., -1.7992e-02,\n",
      "         -9.2896e-03,  1.1733e-02],\n",
      "        [-1.2373e-02, -6.9049e-03,  0.0000e+00,  ..., -7.5095e-03,\n",
      "         -4.4819e-03, -0.0000e+00]], grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output\n",
      "tensor([[ 0.5687,  0.2775,  0.1449,  ...,  0.1225,  0.0834,  0.4544],\n",
      "        [-0.3766,  0.0708, -0.1322,  ...,  0.0576, -0.2987, -0.1473],\n",
      "        [ 0.2488,  0.2048,  0.1348,  ..., -0.0544,  0.1517,  0.0512],\n",
      "        ...,\n",
      "        [ 0.4662,  0.1335, -0.1136,  ...,  0.2857,  0.4390, -0.4144],\n",
      "        [ 0.7278, -0.0537,  0.2692,  ...,  0.1121,  0.2020,  0.5039],\n",
      "        [ 0.0966,  0.1997,  0.0723,  ...,  0.2911, -0.0875, -0.0407]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.2738,  0.0726,  0.3099,  ..., -0.5278,  0.1998,  0.9796],\n",
      "        [ 0.3672, -0.7559,  0.1767,  ..., -0.3984, -0.2536,  0.1650],\n",
      "        [-0.0759,  0.8209, -0.7913,  ...,  0.3599, -0.5397,  0.1616],\n",
      "        ...,\n",
      "        [-0.3081, -0.8463,  0.2813,  ..., -0.1268, -0.1105, -0.0323],\n",
      "        [-0.4048, -0.2035,  0.5139,  ..., -0.1065,  0.2478,  0.3928],\n",
      "        [ 0.1873,  0.2311, -0.0363,  ...,  0.8268,  0.2212, -0.4681]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0000,  ..., -0.0000, -0.0083,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0000,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0000,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0000],\n",
      "        [-0.0188, -0.0165,  0.0000,  ...,  0.0016,  0.0039,  0.0130],\n",
      "        [-0.0000,  0.0047,  0.0036,  ..., -0.0000, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.3221,  1.0416,  0.2090,  ..., -0.3668,  0.1921, -0.0561],\n",
      "        [ 0.4982, -0.0022,  0.8305,  ..., -0.4336, -0.1882, -0.1134],\n",
      "        [-0.4760, -0.2447, -0.0474,  ...,  0.8260, -0.2880, -0.5339],\n",
      "        ...,\n",
      "        [ 0.2746,  0.2509,  0.3581,  ..., -0.5513, -0.0037, -0.0043],\n",
      "        [-0.0313, -0.0503,  0.3498,  ..., -0.3408, -0.0983,  0.2959],\n",
      "        [-0.0364, -0.1893, -0.6874,  ..., -0.0639, -0.0711,  0.0283]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.3221,  1.0416,  0.2090,  ..., -0.3668,  0.1921, -0.0561],\n",
      "        [ 0.4982, -0.0022,  0.8305,  ..., -0.4336, -0.1882, -0.1134],\n",
      "        [-0.4760, -0.2447, -0.0474,  ...,  0.8260, -0.2880, -0.5339],\n",
      "        ...,\n",
      "        [ 0.2746,  0.2509,  0.3581,  ..., -0.5513, -0.0037, -0.0043],\n",
      "        [-0.0313, -0.0503,  0.3498,  ..., -0.3408, -0.0983,  0.2959],\n",
      "        [-0.0364, -0.1893, -0.6874,  ..., -0.0639, -0.0711,  0.0283]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4761e-02, -4.9243e-04,  7.4004e-03,  ..., -1.0204e-02,\n",
      "         -1.4373e-02, -1.5051e-02],\n",
      "        [-7.3659e-03,  1.0699e-02,  6.6973e-03,  ..., -1.3221e-02,\n",
      "         -1.3634e-02, -9.2989e-03],\n",
      "        [-8.2277e-03, -1.4046e-02,  8.8365e-03,  ..., -3.8888e-03,\n",
      "         -1.0035e-02,  1.2660e-02],\n",
      "        ...,\n",
      "        [ 1.3393e-02,  3.8773e-03,  2.1463e-03,  ..., -1.1798e-02,\n",
      "          7.3929e-03, -4.0097e-03],\n",
      "        [ 5.1879e-05,  1.0973e-02, -1.3865e-02,  ..., -1.4394e-02,\n",
      "         -7.4350e-03,  9.3848e-03],\n",
      "        [-9.8887e-03, -5.5185e-03,  3.5893e-03,  ..., -6.0084e-03,\n",
      "         -3.5824e-03, -9.4194e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0000, -0.0006,  0.0000,  ..., -0.0128, -0.0180, -0.0188],\n",
      "        [-0.0092,  0.0000,  0.0084,  ..., -0.0165, -0.0170, -0.0000],\n",
      "        [-0.0103, -0.0176,  0.0110,  ..., -0.0000, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0027,  ..., -0.0147,  0.0092, -0.0050],\n",
      "        [ 0.0000,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0000],\n",
      "        [-0.0124, -0.0069,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.4065, -0.1831,  0.0840,  ..., -0.1339,  0.2461, -0.2311],\n",
      "        [ 0.3478,  0.0023,  0.2723,  ...,  0.0195, -0.0132,  0.2597],\n",
      "        [-0.2963, -0.1912, -0.4252,  ...,  0.1677,  0.1191, -0.1800],\n",
      "        ...,\n",
      "        [ 0.3628, -0.0290,  0.0250,  ...,  0.2048, -0.0052,  0.0609],\n",
      "        [ 0.4248, -0.2271, -0.1060,  ...,  0.0776,  0.0937, -0.2684],\n",
      "        [-0.4226, -0.1014,  0.0578,  ..., -0.0092, -0.1462,  0.2534]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.2386,  0.4035,  0.7056,  ...,  0.6952,  0.5921,  0.4426],\n",
      "        [ 0.0812, -0.6504,  0.3435,  ..., -0.6883, -0.0850,  0.3676],\n",
      "        [ 0.1035, -0.0074,  0.5888,  ..., -0.5736, -0.0058,  0.0450],\n",
      "        ...,\n",
      "        [ 0.5356, -0.1701, -0.1855,  ..., -0.1768, -0.2628,  0.5243],\n",
      "        [ 0.4397,  0.3093,  0.7140,  ..., -0.7762, -0.8187,  0.7857],\n",
      "        [-0.2163,  0.6234, -0.0051,  ...,  0.3527,  0.6862, -0.3310]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0000],\n",
      "        [-0.0167,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0000,  ...,  0.0179, -0.0000,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0000, -0.0000,  0.0000],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0017,  0.0039,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.2403,  0.2583, -0.4242,  ...,  0.3041,  0.0241,  0.1394],\n",
      "        [ 0.1342,  0.4891,  0.4452,  ..., -0.3121, -0.0126,  0.3454],\n",
      "        [ 0.1788,  0.1592,  0.3483,  ..., -0.0301, -0.4830,  0.2307],\n",
      "        ...,\n",
      "        [-0.4293,  0.1871,  0.1686,  ..., -0.0948, -0.0666, -0.0805],\n",
      "        [-0.3366,  0.3306,  0.2955,  ...,  0.1781, -0.1378,  0.2819],\n",
      "        [-0.4968,  0.1735, -0.1344,  ..., -0.2428,  0.0517,  0.1582]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.2403,  0.2583, -0.4242,  ...,  0.3041,  0.0241,  0.1394],\n",
      "        [ 0.1342,  0.4891,  0.4452,  ..., -0.3121, -0.0126,  0.3454],\n",
      "        [ 0.1788,  0.1592,  0.3483,  ..., -0.0301, -0.4830,  0.2307],\n",
      "        ...,\n",
      "        [-0.4293,  0.1871,  0.1686,  ..., -0.0948, -0.0666, -0.0805],\n",
      "        [-0.3366,  0.3306,  0.2955,  ...,  0.1781, -0.1378,  0.2819],\n",
      "        [-0.4968,  0.1735, -0.1344,  ..., -0.2428,  0.0517,  0.1582]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4761e-02, -4.9696e-04,  7.4004e-03,  ..., -1.0206e-02,\n",
      "         -1.4371e-02, -1.5052e-02],\n",
      "        [-7.3598e-03,  1.0699e-02,  6.7016e-03,  ..., -1.3220e-02,\n",
      "         -1.3633e-02, -9.2989e-03],\n",
      "        [-8.2244e-03, -1.4049e-02,  8.8394e-03,  ..., -3.8888e-03,\n",
      "         -1.0036e-02,  1.2662e-02],\n",
      "        ...,\n",
      "        [ 1.3393e-02,  3.8773e-03,  2.1500e-03,  ..., -1.1795e-02,\n",
      "          7.3954e-03, -4.0122e-03],\n",
      "        [ 5.1879e-05,  1.0978e-02, -1.3870e-02,  ..., -1.4393e-02,\n",
      "         -7.4360e-03,  9.3848e-03],\n",
      "        [-9.8808e-03, -5.5218e-03,  3.5947e-03,  ..., -6.0105e-03,\n",
      "         -3.5805e-03, -9.4185e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0185, -0.0000,  0.0093,  ..., -0.0128, -0.0000, -0.0000],\n",
      "        [-0.0092,  0.0000,  0.0000,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0000,  0.0110,  ..., -0.0049, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0048,  0.0027,  ..., -0.0147,  0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0117],\n",
      "        [-0.0000, -0.0069,  0.0045,  ..., -0.0000, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.5911,  0.0921, -0.1881,  ..., -0.4682, -0.0469, -0.1033],\n",
      "        [ 0.2666,  0.3707, -0.1098,  ...,  0.2212, -0.1537,  0.4286],\n",
      "        [ 0.3323,  0.0249, -0.0505,  ...,  0.2768, -0.0584,  0.0270],\n",
      "        ...,\n",
      "        [-0.0096,  0.2026,  0.1300,  ...,  0.0876, -0.1604,  0.2870],\n",
      "        [ 0.1059, -0.0354, -0.0763,  ...,  0.3200, -0.1664,  0.1725],\n",
      "        [ 0.2560, -0.2044,  0.0104,  ..., -0.2125,  0.0622,  0.3125]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[-0.2252,  0.1049, -0.2784,  ..., -0.2082,  0.5977, -0.1085],\n",
      "        [-0.2289, -0.1967,  0.1503,  ..., -0.4792,  0.4595, -0.6064],\n",
      "        [-0.6440,  0.1456,  0.2772,  ...,  0.3803,  0.2928,  0.4054],\n",
      "        ...,\n",
      "        [ 0.3007, -0.2176, -0.1169,  ...,  0.2967,  0.4250, -0.2317],\n",
      "        [-0.0396,  0.9081, -0.5022,  ...,  0.3470,  0.0436, -0.6460],\n",
      "        [ 0.5399,  0.2241, -0.4753,  ...,  0.1732, -0.4802, -0.2562]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0168,  0.0000,  0.0000,  ..., -0.0169, -0.0068, -0.0000],\n",
      "        [ 0.0057,  0.0000,  0.0039,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0000, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0017,  0.0039,  0.0130],\n",
      "        [-0.0066,  0.0000,  0.0036,  ..., -0.0000, -0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.1300,  0.2051,  0.4682,  ..., -0.1693, -0.1842, -0.1941],\n",
      "        [-0.0771,  0.3782, -0.1516,  ...,  1.0369,  0.2077, -0.3939],\n",
      "        [-0.1824,  0.0060,  0.7322,  ..., -0.1204, -0.6469,  0.2782],\n",
      "        ...,\n",
      "        [ 0.1338, -0.2489,  1.0127,  ..., -0.0781, -0.1778, -0.4745],\n",
      "        [-0.0684, -0.1889, -0.9135,  ...,  0.5946,  0.0284, -0.2264],\n",
      "        [ 0.0722, -0.5109, -0.5245,  ...,  0.4918,  0.0794, -0.1923]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.1300,  0.2051,  0.4682,  ..., -0.1693, -0.1842, -0.1941],\n",
      "        [-0.0771,  0.3782, -0.1516,  ...,  1.0369,  0.2077, -0.3939],\n",
      "        [-0.1824,  0.0060,  0.7322,  ..., -0.1204, -0.6469,  0.2782],\n",
      "        ...,\n",
      "        [ 0.1338, -0.2489,  1.0127,  ..., -0.0781, -0.1778, -0.4745],\n",
      "        [-0.0684, -0.1889, -0.9135,  ...,  0.5946,  0.0284, -0.2264],\n",
      "        [ 0.0722, -0.5109, -0.5245,  ...,  0.4918,  0.0794, -0.1923]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4765e-02, -4.9696e-04,  7.4008e-03,  ..., -1.0204e-02,\n",
      "         -1.4371e-02, -1.5052e-02],\n",
      "        [-7.3568e-03,  1.0699e-02,  6.7016e-03,  ..., -1.3220e-02,\n",
      "         -1.3632e-02, -9.2960e-03],\n",
      "        [-8.2208e-03, -1.4049e-02,  8.8403e-03,  ..., -3.8870e-03,\n",
      "         -1.0038e-02,  1.2662e-02],\n",
      "        ...,\n",
      "        [ 1.3392e-02,  3.8743e-03,  2.1487e-03,  ..., -1.1794e-02,\n",
      "          7.3954e-03, -4.0122e-03],\n",
      "        [ 5.1879e-05,  1.0977e-02, -1.3872e-02,  ..., -1.4394e-02,\n",
      "         -7.4360e-03,  9.3834e-03],\n",
      "        [-9.8808e-03, -5.5234e-03,  3.5933e-03,  ..., -6.0105e-03,\n",
      "         -3.5799e-03, -9.4209e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0185, -0.0000,  0.0093,  ..., -0.0128, -0.0180, -0.0188],\n",
      "        [-0.0092,  0.0134,  0.0084,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0176,  0.0111,  ..., -0.0049, -0.0125,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0048,  0.0027,  ..., -0.0147,  0.0092, -0.0050],\n",
      "        [ 0.0000,  0.0137, -0.0173,  ..., -0.0180, -0.0093,  0.0117],\n",
      "        [-0.0124, -0.0000,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.1073, -0.0228,  0.2006,  ..., -0.0194,  0.0503, -0.0296],\n",
      "        [-0.3503,  0.0570,  0.0099,  ..., -0.1809,  0.0236, -0.0688],\n",
      "        [ 0.5516, -0.0611,  0.1316,  ...,  0.4057,  0.0385,  0.2045],\n",
      "        ...,\n",
      "        [ 0.1153,  0.4067,  0.2139,  ...,  0.4397,  0.0429, -0.0108],\n",
      "        [-0.3503, -0.4117, -0.0183,  ..., -0.0969, -0.0790, -0.2082],\n",
      "        [-0.2678,  0.0553, -0.1494,  ..., -0.2317, -0.1072, -0.2106]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 4.3203e-01, -3.2496e-01,  3.0607e-01,  ..., -4.6077e-01,\n",
      "         -7.9547e-01,  1.0323e-01],\n",
      "        [ 6.6212e-02, -1.6996e-01,  3.7722e-01,  ..., -2.3000e-01,\n",
      "         -1.3882e-01, -1.6677e-01],\n",
      "        [-9.3785e-02, -3.5705e-01, -5.3304e-01,  ...,  3.9445e-01,\n",
      "         -1.1522e-01, -4.3383e-01],\n",
      "        ...,\n",
      "        [-4.9032e-01, -3.3917e-01,  3.8640e-01,  ..., -4.3382e-01,\n",
      "          7.9379e-01,  5.2990e-01],\n",
      "        [ 4.1916e-01, -4.5538e-04,  5.3288e-03,  ..., -1.5012e+00,\n",
      "         -2.5085e-01,  3.0900e-01],\n",
      "        [ 4.1956e-01, -7.4902e-03,  8.5556e-01,  ...,  5.3698e-01,\n",
      "         -4.2661e-02,  6.7041e-01]], grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0000, -0.0083,  0.0072],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0000,  0.0044,  0.0000,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0000,  0.0074, -0.0086,  ...,  0.0000, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0000,  0.0017,  ...,  0.0000,  0.0039,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.1952,  0.0891,  0.1225,  ..., -0.1651,  0.0123,  0.0630],\n",
      "        [ 0.2736, -0.4751,  0.5597,  ...,  0.0095, -0.2709, -0.1602],\n",
      "        [ 0.0361,  0.1988,  0.3020,  ..., -0.3933, -0.1382, -0.1561],\n",
      "        ...,\n",
      "        [ 0.2860,  0.3798,  0.4916,  ..., -0.4318, -0.2561,  0.4133],\n",
      "        [ 0.1946,  0.2248,  0.9369,  ..., -0.3754, -0.6485,  0.3482],\n",
      "        [-0.1735, -0.4105, -0.2703,  ..., -0.7331, -0.2661, -0.1256]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.1952,  0.0891,  0.1225,  ..., -0.1651,  0.0123,  0.0630],\n",
      "        [ 0.2736, -0.4751,  0.5597,  ...,  0.0095, -0.2709, -0.1602],\n",
      "        [ 0.0361,  0.1988,  0.3020,  ..., -0.3933, -0.1382, -0.1561],\n",
      "        ...,\n",
      "        [ 0.2860,  0.3798,  0.4916,  ..., -0.4318, -0.2561,  0.4133],\n",
      "        [ 0.1946,  0.2248,  0.9369,  ..., -0.3754, -0.6485,  0.3482],\n",
      "        [-0.1735, -0.4105, -0.2703,  ..., -0.7331, -0.2661, -0.1256]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4770e-02, -4.9696e-04,  7.4043e-03,  ..., -1.0207e-02,\n",
      "         -1.4372e-02, -1.5049e-02],\n",
      "        [-7.3553e-03,  1.0700e-02,  6.7044e-03,  ..., -1.3221e-02,\n",
      "         -1.3634e-02, -9.2946e-03],\n",
      "        [-8.2231e-03, -1.4047e-02,  8.8445e-03,  ..., -3.8851e-03,\n",
      "         -1.0041e-02,  1.2665e-02],\n",
      "        ...,\n",
      "        [ 1.3390e-02,  3.8721e-03,  2.1475e-03,  ..., -1.1794e-02,\n",
      "          7.3963e-03, -4.0157e-03],\n",
      "        [ 5.1879e-05,  1.0972e-02, -1.3878e-02,  ..., -1.4390e-02,\n",
      "         -7.4362e-03,  9.3776e-03],\n",
      "        [-9.8784e-03, -5.5234e-03,  3.5967e-03,  ..., -6.0120e-03,\n",
      "         -3.5800e-03, -9.4183e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8462e-02, -6.2121e-04,  9.2554e-03,  ..., -1.2759e-02,\n",
      "         -1.7965e-02, -1.8812e-02],\n",
      "        [-9.1942e-03,  1.3375e-02,  8.3805e-03,  ..., -0.0000e+00,\n",
      "         -1.7042e-02, -0.0000e+00],\n",
      "        [-1.0279e-02, -1.7559e-02,  0.0000e+00,  ..., -4.8564e-03,\n",
      "         -1.2552e-02,  1.5831e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  4.8401e-03,  2.6844e-03,  ..., -0.0000e+00,\n",
      "          0.0000e+00, -5.0196e-03],\n",
      "        [ 6.4849e-05,  0.0000e+00, -1.7347e-02,  ..., -1.7987e-02,\n",
      "         -9.2952e-03,  1.1722e-02],\n",
      "        [-1.2348e-02, -0.0000e+00,  4.4959e-03,  ..., -7.5150e-03,\n",
      "         -4.4750e-03, -1.1773e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.1945, -0.1391, -0.0377,  ...,  0.1223,  0.2145,  0.0492],\n",
      "        [ 0.0191,  0.0745, -0.0511,  ...,  0.0585,  0.3207, -0.2222],\n",
      "        [ 0.0364,  0.1533, -0.0806,  ...,  0.1202,  0.0447,  0.2864],\n",
      "        ...,\n",
      "        [ 0.4796, -0.0161,  0.1634,  ..., -0.0696, -0.1451,  0.1399],\n",
      "        [ 0.5891,  0.2743,  0.3682,  ...,  0.6708,  0.0274, -0.0211],\n",
      "        [ 0.2911, -0.4519, -0.0383,  ..., -0.0386, -0.3718,  0.4482]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [5120/40000 (13%)]\tLoss: 2.120920\n",
      "Input\n",
      "tensor([[ 0.2273, -0.1942, -0.1955,  ..., -0.6947,  0.1577,  0.1611],\n",
      "        [-0.2490,  0.0209,  0.4570,  ..., -0.8231, -0.4694,  0.3864],\n",
      "        [ 0.6035, -0.4816, -0.3017,  ...,  0.2972, -0.3598, -0.0076],\n",
      "        ...,\n",
      "        [ 0.0070, -0.1235,  0.0361,  ..., -0.5691,  0.3617, -0.1907],\n",
      "        [-0.0822,  0.3761,  0.5301,  ..., -0.0609,  0.1546, -0.1570],\n",
      "        [ 0.3235, -0.0522, -1.0109,  ..., -0.3419,  0.4597, -0.5342]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0168,  0.0051,  0.0002,  ..., -0.0169, -0.0000, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0000,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0000],\n",
      "        [-0.0188, -0.0000,  0.0017,  ...,  0.0017,  0.0039,  0.0130],\n",
      "        [-0.0000,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.4151,  0.1809,  0.1049,  ..., -0.1153, -0.1111, -0.0687],\n",
      "        [ 0.6942, -0.3562,  0.3990,  ...,  0.4446, -0.0474,  0.0660],\n",
      "        [-0.2753, -0.1939,  0.0541,  ...,  0.5469, -0.1487, -0.2148],\n",
      "        ...,\n",
      "        [ 0.7149, -0.4482,  0.1204,  ..., -0.0633,  0.1108, -0.3022],\n",
      "        [-0.1661, -0.3022, -0.1865,  ...,  0.3857,  0.0308, -0.1926],\n",
      "        [ 0.5158,  0.1294,  0.4551,  ..., -0.3474,  0.3383, -0.5582]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.4151,  0.1809,  0.1049,  ..., -0.1153, -0.1111, -0.0687],\n",
      "        [ 0.6942, -0.3562,  0.3990,  ...,  0.4446, -0.0474,  0.0660],\n",
      "        [-0.2753, -0.1939,  0.0541,  ...,  0.5469, -0.1487, -0.2148],\n",
      "        ...,\n",
      "        [ 0.7149, -0.4482,  0.1204,  ..., -0.0633,  0.1108, -0.3022],\n",
      "        [-0.1661, -0.3022, -0.1865,  ...,  0.3857,  0.0308, -0.1926],\n",
      "        [ 0.5158,  0.1294,  0.4551,  ..., -0.3474,  0.3383, -0.5582]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4778e-02, -4.9253e-04,  7.4084e-03,  ..., -1.0211e-02,\n",
      "         -1.4372e-02, -1.5047e-02],\n",
      "        [-7.3499e-03,  1.0701e-02,  6.7063e-03,  ..., -1.3221e-02,\n",
      "         -1.3634e-02, -9.2946e-03],\n",
      "        [-8.2201e-03, -1.4047e-02,  8.8445e-03,  ..., -3.8824e-03,\n",
      "         -1.0044e-02,  1.2667e-02],\n",
      "        ...,\n",
      "        [ 1.3390e-02,  3.8658e-03,  2.1457e-03,  ..., -1.1794e-02,\n",
      "          7.3963e-03, -4.0158e-03],\n",
      "        [ 4.2004e-05,  1.0972e-02, -1.3883e-02,  ..., -1.4386e-02,\n",
      "         -7.4357e-03,  9.3749e-03],\n",
      "        [-9.8706e-03, -5.5234e-03,  3.6018e-03,  ..., -6.0133e-03,\n",
      "         -3.5822e-03, -9.4140e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8472e-02, -6.1566e-04,  0.0000e+00,  ..., -1.2763e-02,\n",
      "         -1.7965e-02, -1.8809e-02],\n",
      "        [-9.1873e-03,  0.0000e+00,  8.3828e-03,  ..., -1.6527e-02,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [-1.0275e-02, -0.0000e+00,  1.1056e-02,  ..., -4.8530e-03,\n",
      "         -1.2555e-02,  1.5834e-02],\n",
      "        ...,\n",
      "        [ 1.6737e-02,  4.8322e-03,  0.0000e+00,  ..., -1.4742e-02,\n",
      "          9.2454e-03, -0.0000e+00],\n",
      "        [ 5.2505e-05,  1.3715e-02, -1.7354e-02,  ..., -0.0000e+00,\n",
      "         -9.2947e-03,  0.0000e+00],\n",
      "        [-1.2338e-02, -6.9043e-03,  4.5022e-03,  ..., -7.5167e-03,\n",
      "         -0.0000e+00, -1.1767e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.1295,  0.3235,  0.1856,  ..., -0.0809,  0.1994, -0.1081],\n",
      "        [-0.1913, -0.0430,  0.0350,  ...,  0.4746,  0.1783, -0.3924],\n",
      "        [-0.4909,  0.1569,  0.0765,  ...,  0.2943,  0.2731,  0.0986],\n",
      "        ...,\n",
      "        [ 0.1787, -0.0298,  0.1273,  ...,  0.3386,  0.0459, -0.2919],\n",
      "        [-0.2789, -0.2308,  0.0791,  ...,  0.0371,  0.0277, -0.2241],\n",
      "        [ 0.1422,  0.0385, -0.0693,  ...,  0.5533,  0.0311, -0.0617]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.2595, -0.1794,  0.5447,  ...,  0.2391, -0.5146,  0.4064],\n",
      "        [ 0.4633,  0.1301, -0.2504,  ...,  0.2621,  0.3033,  0.0415],\n",
      "        [-0.1908, -0.4288,  0.2845,  ...,  0.1985, -0.0567, -0.3824],\n",
      "        ...,\n",
      "        [ 0.3754,  0.7250,  0.7006,  ..., -0.0253,  0.0560, -0.3999],\n",
      "        [ 0.1143,  0.9394, -0.1639,  ...,  0.7769, -0.3275,  0.1830],\n",
      "        [ 0.3685,  0.3355,  0.0721,  ...,  0.9408, -0.2847,  0.2002]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0069,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0000,  0.0044,  0.0040,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0000,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0000,  0.0039,  0.0130],\n",
      "        [-0.0000,  0.0047,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.0773,  0.2530, -0.0688,  ...,  0.3070, -0.1331, -0.1344],\n",
      "        [-0.1018, -0.4356, -0.4823,  ...,  0.1110, -0.1599, -0.3024],\n",
      "        [ 0.7114,  0.2054,  0.4656,  ..., -0.1887,  0.0426, -0.2346],\n",
      "        ...,\n",
      "        [ 0.1476, -0.0751, -0.4002,  ...,  0.7850, -0.3749,  0.2404],\n",
      "        [-0.0365, -1.0287, -1.1167,  ...,  0.6523,  0.1446, -0.9032],\n",
      "        [-0.2656, -0.4941, -1.1578,  ...,  0.4013,  0.0491, -0.0465]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.0773,  0.2530, -0.0688,  ...,  0.3070, -0.1331, -0.1344],\n",
      "        [-0.1018, -0.4356, -0.4823,  ...,  0.1110, -0.1599, -0.3024],\n",
      "        [ 0.7114,  0.2054,  0.4656,  ..., -0.1887,  0.0426, -0.2346],\n",
      "        ...,\n",
      "        [ 0.1476, -0.0751, -0.4002,  ...,  0.7850, -0.3749,  0.2404],\n",
      "        [-0.0365, -1.0287, -1.1167,  ...,  0.6523,  0.1446, -0.9032],\n",
      "        [-0.2656, -0.4941, -1.1578,  ...,  0.4013,  0.0491, -0.0465]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4787e-02, -4.9321e-04,  7.4084e-03,  ..., -1.0210e-02,\n",
      "         -1.4373e-02, -1.5048e-02],\n",
      "        [-7.3457e-03,  1.0701e-02,  6.7075e-03,  ..., -1.3220e-02,\n",
      "         -1.3634e-02, -9.2946e-03],\n",
      "        [-8.2190e-03, -1.4047e-02,  8.8427e-03,  ..., -3.8762e-03,\n",
      "         -1.0046e-02,  1.2668e-02],\n",
      "        ...,\n",
      "        [ 1.3391e-02,  3.8703e-03,  2.1457e-03,  ..., -1.1799e-02,\n",
      "          7.3970e-03, -4.0158e-03],\n",
      "        [ 3.5415e-05,  1.0978e-02, -1.3879e-02,  ..., -1.4386e-02,\n",
      "         -7.4352e-03,  9.3749e-03],\n",
      "        [-9.8646e-03, -5.5249e-03,  3.6007e-03,  ..., -6.0097e-03,\n",
      "         -3.5822e-03, -9.4159e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8484e-02, -0.0000e+00,  0.0000e+00,  ..., -1.2762e-02,\n",
      "         -1.7966e-02, -1.8810e-02],\n",
      "        [-9.1822e-03,  0.0000e+00,  8.3844e-03,  ..., -1.6525e-02,\n",
      "         -1.7042e-02, -0.0000e+00],\n",
      "        [-1.0274e-02, -1.7559e-02,  0.0000e+00,  ..., -4.8452e-03,\n",
      "         -1.2557e-02,  1.5835e-02],\n",
      "        ...,\n",
      "        [ 1.6739e-02,  4.8379e-03,  0.0000e+00,  ..., -1.4748e-02,\n",
      "          9.2462e-03, -5.0198e-03],\n",
      "        [ 4.4269e-05,  1.3723e-02, -1.7349e-02,  ..., -1.7983e-02,\n",
      "         -9.2940e-03,  1.1719e-02],\n",
      "        [-1.2331e-02, -6.9061e-03,  0.0000e+00,  ..., -7.5121e-03,\n",
      "         -4.4778e-03, -1.1770e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.0249,  0.1692,  0.0971,  ...,  0.1310,  0.1750,  0.0412],\n",
      "        [-0.3521, -0.0928, -0.0690,  ...,  0.1557, -0.1902,  0.3944],\n",
      "        [ 0.1635,  0.0814,  0.0676,  ...,  0.1056,  0.3323,  0.3236],\n",
      "        ...,\n",
      "        [ 0.0396,  0.0485,  0.0697,  ..., -0.0602,  0.0668, -0.2166],\n",
      "        [-0.5738,  0.0330,  0.0034,  ..., -0.4016, -0.0686, -0.5891],\n",
      "        [-0.5770,  0.0053,  0.0299,  ..., -0.2771, -0.2087, -0.3116]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[ 0.2807, -0.4702,  1.0971,  ...,  0.4877, -0.1627, -0.5950],\n",
      "        [-0.1707, -0.3776, -0.1558,  ..., -0.1179,  0.4133,  0.0236],\n",
      "        [-0.7995,  0.2304,  0.5847,  ..., -0.2343, -0.5242,  0.8320],\n",
      "        ...,\n",
      "        [ 0.1608, -0.8074,  0.3171,  ..., -0.6543,  0.7850,  0.5416],\n",
      "        [ 0.0915,  0.3966, -0.7827,  ...,  0.4213, -0.0606, -0.4392],\n",
      "        [-0.0619,  0.0524, -0.1641,  ..., -0.0914, -0.0491, -0.2145]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0068,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0000],\n",
      "        [-0.0000,  0.0051,  0.0002,  ..., -0.0000, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0040,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0000, -0.0165,  0.0017,  ...,  0.0017,  0.0039,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0036,  ..., -0.0104, -0.0144,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.2538, -1.0425, -0.3336,  ...,  0.7770, -0.6582,  0.4866],\n",
      "        [ 0.0765,  0.2617,  0.3641,  ..., -0.4694,  0.0042,  0.1495],\n",
      "        [-0.5306, -0.3879, -0.4109,  ...,  0.2438, -0.0106,  0.4354],\n",
      "        ...,\n",
      "        [ 0.4421,  0.4327,  0.7370,  ..., -0.8329,  0.0879,  0.6082],\n",
      "        [-0.5814, -0.0670, -0.5395,  ...,  0.7694, -0.4849, -0.3460],\n",
      "        [ 0.2872,  0.1013,  0.5795,  ...,  0.0780, -0.2496, -0.2988]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.2538, -1.0425, -0.3336,  ...,  0.7770, -0.6582,  0.4866],\n",
      "        [ 0.0765,  0.2617,  0.3641,  ..., -0.4694,  0.0042,  0.1495],\n",
      "        [-0.5306, -0.3879, -0.4109,  ...,  0.2438, -0.0106,  0.4354],\n",
      "        ...,\n",
      "        [ 0.4421,  0.4327,  0.7370,  ..., -0.8329,  0.0879,  0.6082],\n",
      "        [-0.5814, -0.0670, -0.5395,  ...,  0.7694, -0.4849, -0.3460],\n",
      "        [ 0.2872,  0.1013,  0.5795,  ...,  0.0780, -0.2496, -0.2988]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4790e-02, -4.9321e-04,  7.4084e-03,  ..., -1.0212e-02,\n",
      "         -1.4374e-02, -1.5049e-02],\n",
      "        [-7.3433e-03,  1.0701e-02,  6.7077e-03,  ..., -1.3218e-02,\n",
      "         -1.3634e-02, -9.2946e-03],\n",
      "        [-8.2195e-03, -1.4045e-02,  8.8427e-03,  ..., -3.8774e-03,\n",
      "         -1.0050e-02,  1.2669e-02],\n",
      "        ...,\n",
      "        [ 1.3396e-02,  3.8718e-03,  2.1457e-03,  ..., -1.1797e-02,\n",
      "          7.3966e-03, -4.0163e-03],\n",
      "        [ 3.2053e-05,  1.0976e-02, -1.3886e-02,  ..., -1.4385e-02,\n",
      "         -7.4331e-03,  9.3740e-03],\n",
      "        [-9.8607e-03, -5.5197e-03,  3.6007e-03,  ..., -6.0127e-03,\n",
      "         -3.5851e-03, -9.4163e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8488e-02, -6.1652e-04,  9.2605e-03,  ..., -1.2765e-02,\n",
      "         -1.7967e-02, -0.0000e+00],\n",
      "        [-9.1791e-03,  1.3376e-02,  0.0000e+00,  ..., -1.6523e-02,\n",
      "         -1.7043e-02, -1.1618e-02],\n",
      "        [-1.0274e-02, -0.0000e+00,  0.0000e+00,  ..., -4.8468e-03,\n",
      "         -1.2562e-02,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.6745e-02,  4.8397e-03,  2.6821e-03,  ..., -1.4746e-02,\n",
      "          9.2458e-03, -5.0204e-03],\n",
      "        [ 4.0066e-05,  1.3720e-02, -1.7357e-02,  ..., -1.7981e-02,\n",
      "         -9.2914e-03,  0.0000e+00],\n",
      "        [-1.2326e-02, -6.8996e-03,  0.0000e+00,  ..., -7.5158e-03,\n",
      "         -4.4813e-03, -1.1770e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.4459, -0.2444, -0.2301,  ...,  0.1548,  0.1381,  0.2363],\n",
      "        [ 0.0743,  0.0550, -0.0352,  ...,  0.0816, -0.0570,  0.3823],\n",
      "        [ 0.0138, -0.1178,  0.2051,  ...,  0.4491, -0.3635,  0.1149],\n",
      "        ...,\n",
      "        [ 0.5973,  0.6602,  0.0325,  ...,  0.0637, -0.2486,  0.9811],\n",
      "        [-0.3355, -0.5090, -0.3199,  ..., -0.5386,  0.2312, -0.4187],\n",
      "        [-0.2772,  0.1097, -0.0577,  ...,  0.1147,  0.5377, -0.2365]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[ 0.4394, -0.0395,  0.0808,  ..., -0.3398, -0.5289,  0.1744],\n",
      "        [ 0.1502,  1.1239, -0.8053,  ..., -0.3449, -0.6169,  0.6409],\n",
      "        [-0.4065, -0.0530, -0.0250,  ..., -0.0946, -0.3501, -0.0639],\n",
      "        ...,\n",
      "        [-0.2152,  0.9161,  0.0878,  ...,  0.2132,  0.5555, -0.1303],\n",
      "        [ 0.2134,  0.2802,  0.6720,  ..., -0.2576, -0.0363, -0.1724],\n",
      "        [-0.1984, -0.5196,  0.0749,  ..., -0.0600, -0.0152, -0.0478]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0068,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0168,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0000],\n",
      "        [ 0.0057,  0.0044,  0.0040,  ...,  0.0179, -0.0120,  0.0000],\n",
      "        ...,\n",
      "        [-0.0000,  0.0074, -0.0000,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0000,  ...,  0.0017,  0.0039,  0.0000],\n",
      "        [-0.0066,  0.0047,  0.0000,  ..., -0.0000, -0.0145,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.1029, -0.1156,  0.1092,  ...,  0.3827, -0.3277,  0.1764],\n",
      "        [-1.2328,  0.2237, -0.1148,  ...,  0.4517,  0.4701,  0.0380],\n",
      "        [-0.1028,  0.0352, -0.2743,  ..., -0.0900,  0.2916,  0.4097],\n",
      "        ...,\n",
      "        [-0.8197,  0.3457, -0.0926,  ..., -0.2303,  0.1789, -0.0367],\n",
      "        [ 0.1606, -0.3709, -0.0990,  ...,  0.2922,  0.1169,  0.1507],\n",
      "        [ 0.4225,  0.6393,  0.0544,  ..., -0.9121, -0.0712, -0.1633]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.1029, -0.1156,  0.1092,  ...,  0.3827, -0.3277,  0.1764],\n",
      "        [-1.2328,  0.2237, -0.1148,  ...,  0.4517,  0.4701,  0.0380],\n",
      "        [-0.1028,  0.0352, -0.2743,  ..., -0.0900,  0.2916,  0.4097],\n",
      "        ...,\n",
      "        [-0.8197,  0.3457, -0.0926,  ..., -0.2303,  0.1789, -0.0367],\n",
      "        [ 0.1606, -0.3709, -0.0990,  ...,  0.2922,  0.1169,  0.1507],\n",
      "        [ 0.4225,  0.6393,  0.0544,  ..., -0.9121, -0.0712, -0.1633]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4796e-02, -4.9628e-04,  7.4081e-03,  ..., -1.0212e-02,\n",
      "         -1.4373e-02, -1.5049e-02],\n",
      "        [-7.3403e-03,  1.0700e-02,  6.7077e-03,  ..., -1.3221e-02,\n",
      "         -1.3632e-02, -9.2954e-03],\n",
      "        [-8.2197e-03, -1.4045e-02,  8.8427e-03,  ..., -3.8774e-03,\n",
      "         -1.0050e-02,  1.2669e-02],\n",
      "        ...,\n",
      "        [ 1.3398e-02,  3.8742e-03,  2.1486e-03,  ..., -1.1801e-02,\n",
      "          7.4011e-03, -4.0149e-03],\n",
      "        [ 2.4146e-05,  1.0978e-02, -1.3889e-02,  ..., -1.4384e-02,\n",
      "         -7.4361e-03,  9.3740e-03],\n",
      "        [-9.8545e-03, -5.5217e-03,  3.6007e-03,  ..., -6.0120e-03,\n",
      "         -3.5840e-03, -9.4167e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 1.8495e-02, -0.0000e+00,  9.2601e-03,  ..., -1.2765e-02,\n",
      "         -1.7966e-02, -0.0000e+00],\n",
      "        [-9.1754e-03,  1.3375e-02,  8.3846e-03,  ..., -1.6526e-02,\n",
      "         -1.7040e-02, -1.1619e-02],\n",
      "        [-1.0275e-02, -0.0000e+00,  1.1053e-02,  ..., -0.0000e+00,\n",
      "         -1.2562e-02,  1.5837e-02],\n",
      "        ...,\n",
      "        [ 1.6747e-02,  4.8428e-03,  2.6858e-03,  ..., -0.0000e+00,\n",
      "          9.2514e-03, -5.0186e-03],\n",
      "        [ 3.0182e-05,  1.3722e-02, -1.7362e-02,  ..., -1.7980e-02,\n",
      "         -9.2951e-03,  1.1717e-02],\n",
      "        [-1.2318e-02, -6.9021e-03,  4.5008e-03,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -1.1771e-02]], grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.0239,  0.1289,  0.0381,  ...,  0.6058,  0.0692,  0.1401],\n",
      "        [-0.4471,  0.0766,  0.3817,  ..., -0.1917,  0.1256, -0.5994],\n",
      "        [ 0.3133,  0.1641, -0.1719,  ...,  0.0843, -0.3082, -0.2193],\n",
      "        ...,\n",
      "        [-0.2984,  0.0567, -0.0181,  ..., -0.5576, -0.1644,  0.0388],\n",
      "        [-0.2136, -0.2172,  0.0799,  ...,  0.2761,  0.1243, -0.2404],\n",
      "        [ 0.3956,  0.4885, -0.0191,  ...,  0.0594,  0.1366, -0.0423]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "tensor([[-0.0935, -0.5977,  0.4761,  ..., -0.2387,  0.2612,  0.1431],\n",
      "        [ 0.0605, -0.0308, -0.0093,  ..., -0.7255,  0.7560,  0.4790],\n",
      "        [ 0.2331,  0.0959, -0.0318,  ..., -0.2216,  0.1467,  0.0819],\n",
      "        ...,\n",
      "        [ 0.5841,  0.5379, -0.0378,  ...,  0.3983, -0.3615, -0.2017],\n",
      "        [ 0.1925,  0.3776,  0.2027,  ..., -0.4162,  0.1437, -0.5447],\n",
      "        [-0.3982, -0.7091, -0.4193,  ..., -0.2476,  0.6549,  0.2162]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0045,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0068,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0000,  ..., -0.0000, -0.0083,  0.0072],\n",
      "        [-0.0168,  0.0051,  0.0002,  ..., -0.0169, -0.0068, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0000,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0017,  0.0000,  0.0130],\n",
      "        [-0.0066,  0.0047,  0.0036,  ..., -0.0104, -0.0145,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.0479,  0.5376,  0.2923,  ..., -0.5478, -0.3487,  0.4279],\n",
      "        [-0.2935, -0.0747,  0.1660,  ..., -0.4522, -0.0238,  0.2418],\n",
      "        [ 0.0166, -0.1278, -0.1256,  ..., -0.0031,  0.0124, -0.0663],\n",
      "        ...,\n",
      "        [ 0.3374, -0.7428, -0.4193,  ...,  0.3783, -0.5862, -0.0926],\n",
      "        [ 0.1921, -0.1027,  0.3364,  ...,  0.3309, -0.0472,  0.0937],\n",
      "        [-0.4380,  0.5786,  0.5953,  ..., -0.7163, -0.0946,  0.6198]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.0479,  0.5376,  0.2923,  ..., -0.5478, -0.3487,  0.4279],\n",
      "        [-0.2935, -0.0747,  0.1660,  ..., -0.4522, -0.0238,  0.2418],\n",
      "        [ 0.0166, -0.1278, -0.1256,  ..., -0.0031,  0.0124, -0.0663],\n",
      "        ...,\n",
      "        [ 0.3374, -0.7428, -0.4193,  ...,  0.3783, -0.5862, -0.0926],\n",
      "        [ 0.1921, -0.1027,  0.3364,  ...,  0.3309, -0.0472,  0.0937],\n",
      "        [-0.4380,  0.5786,  0.5953,  ..., -0.7163, -0.0946,  0.6198]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4804e-02, -4.9628e-04,  7.4087e-03,  ..., -1.0211e-02,\n",
      "         -1.4374e-02, -1.5049e-02],\n",
      "        [-7.3361e-03,  1.0700e-02,  6.7066e-03,  ..., -1.3221e-02,\n",
      "         -1.3633e-02, -9.2954e-03],\n",
      "        [-8.2153e-03, -1.4045e-02,  8.8442e-03,  ..., -3.8774e-03,\n",
      "         -1.0054e-02,  1.2670e-02],\n",
      "        ...,\n",
      "        [ 1.3398e-02,  3.8719e-03,  2.1457e-03,  ..., -1.1801e-02,\n",
      "          7.4031e-03, -4.0124e-03],\n",
      "        [ 1.3707e-05,  1.0975e-02, -1.3891e-02,  ..., -1.4384e-02,\n",
      "         -7.4341e-03,  9.3738e-03],\n",
      "        [-9.8454e-03, -5.5200e-03,  3.6026e-03,  ..., -6.0120e-03,\n",
      "         -3.5840e-03, -9.4149e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0000, -0.0006,  0.0093,  ..., -0.0128, -0.0180, -0.0000],\n",
      "        [-0.0092,  0.0134,  0.0000,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0176,  0.0111,  ..., -0.0048, -0.0126,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0167,  0.0048,  0.0027,  ..., -0.0148,  0.0093, -0.0050],\n",
      "        [ 0.0000,  0.0000, -0.0174,  ..., -0.0180, -0.0093,  0.0000],\n",
      "        [-0.0123, -0.0069,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 2.7223e-01,  1.3038e-01, -1.4159e-02,  ...,  3.5769e-01,\n",
      "         -2.9055e-02,  1.9309e-01],\n",
      "        [ 1.9207e-01,  1.6209e-01,  9.4291e-02,  ...,  2.7963e-01,\n",
      "         -2.5240e-02,  1.8306e-01],\n",
      "        [ 6.6391e-03,  2.9606e-02,  1.5746e-02,  ..., -5.4729e-03,\n",
      "          3.5978e-04,  7.4724e-02],\n",
      "        ...,\n",
      "        [-2.4913e-01, -3.2379e-01, -2.6618e-02,  ..., -1.4675e-01,\n",
      "          2.4210e-01,  3.2537e-01],\n",
      "        [ 2.8603e-01, -1.2214e-01, -1.2337e-01,  ...,  1.5802e-01,\n",
      "          2.8873e-02,  2.3758e-01],\n",
      "        [ 5.0055e-01, -1.3570e-01,  5.0698e-02,  ..., -3.8901e-02,\n",
      "         -2.4001e-01,  4.7090e-01]], grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-5.1463e-04, -6.9491e-02,  7.3014e-02,  ..., -3.9466e-01,\n",
      "         -4.1687e-01,  8.4776e-02],\n",
      "        [ 5.6707e-01, -6.4339e-01,  6.9053e-01,  ..., -3.0951e-01,\n",
      "         -3.0854e-01,  4.4099e-01],\n",
      "        [ 4.7729e-01, -5.0547e-01,  4.3812e-01,  ..., -3.3990e-01,\n",
      "          4.1794e-01,  1.5133e-02],\n",
      "        ...,\n",
      "        [ 8.7266e-02, -1.9809e-01, -5.7853e-02,  ...,  5.1739e-01,\n",
      "         -3.3560e-01, -1.2832e-01],\n",
      "        [-1.1435e-01,  2.7711e-01,  7.3914e-02,  ..., -8.3286e-01,\n",
      "          5.2279e-02, -4.2255e-01],\n",
      "        [ 5.5150e-02, -3.8362e-01,  7.9160e-01,  ..., -2.7702e-01,\n",
      "         -1.8349e-01,  4.9370e-01]], grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[-0.0007, -0.0155, -0.0143,  ..., -0.0120, -0.0066,  0.0058],\n",
      "        [-0.0134,  0.0041,  0.0002,  ..., -0.0135, -0.0055, -0.0019],\n",
      "        [ 0.0046,  0.0035,  0.0032,  ...,  0.0143, -0.0096,  0.0028],\n",
      "        ...,\n",
      "        [-0.0148,  0.0059, -0.0068,  ...,  0.0054, -0.0144,  0.0083],\n",
      "        [-0.0151, -0.0132,  0.0014,  ...,  0.0013,  0.0031,  0.0104],\n",
      "        [-0.0053,  0.0038,  0.0029,  ..., -0.0083, -0.0116,  0.0069]],\n",
      "       requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[-0.0009, -0.0194, -0.0179,  ..., -0.0150, -0.0083,  0.0072],\n",
      "        [-0.0168,  0.0051,  0.0002,  ..., -0.0169, -0.0000, -0.0024],\n",
      "        [ 0.0057,  0.0044,  0.0040,  ...,  0.0179, -0.0120,  0.0035],\n",
      "        ...,\n",
      "        [-0.0186,  0.0074, -0.0086,  ...,  0.0067, -0.0180,  0.0104],\n",
      "        [-0.0188, -0.0165,  0.0017,  ...,  0.0017,  0.0039,  0.0130],\n",
      "        [-0.0000,  0.0047,  0.0000,  ..., -0.0000, -0.0145,  0.0086]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[-0.1516,  0.3828,  0.3454,  ...,  0.0019,  0.4007, -0.3195],\n",
      "        [ 0.6449,  0.1604,  0.1156,  ..., -0.1688,  0.4141,  0.2690],\n",
      "        [ 0.5878,  0.1863, -0.0821,  ..., -0.1679,  0.3135,  0.3497],\n",
      "        ...,\n",
      "        [-0.4596, -0.0064,  0.1559,  ..., -0.0938,  0.3763, -0.0138],\n",
      "        [ 0.1817, -0.1800,  0.1873,  ...,  0.4999,  0.3063, -0.2630],\n",
      "        [ 0.1510, -0.2293, -0.1504,  ...,  0.2717, -0.0241, -0.1849]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Input\n",
      "tensor([[-0.1516,  0.3828,  0.3454,  ...,  0.0019,  0.4007, -0.3195],\n",
      "        [ 0.6449,  0.1604,  0.1156,  ..., -0.1688,  0.4141,  0.2690],\n",
      "        [ 0.5878,  0.1863, -0.0821,  ..., -0.1679,  0.3135,  0.3497],\n",
      "        ...,\n",
      "        [-0.4596, -0.0064,  0.1559,  ..., -0.0938,  0.3763, -0.0138],\n",
      "        [ 0.1817, -0.1800,  0.1873,  ...,  0.4999,  0.3063, -0.2630],\n",
      "        [ 0.1510, -0.2293, -0.1504,  ...,  0.2717, -0.0241, -0.1849]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "Self weight\n",
      "Parameter containing:\n",
      "tensor([[ 1.4804e-02, -4.9932e-04,  7.4081e-03,  ..., -1.0207e-02,\n",
      "         -1.4376e-02, -1.5049e-02],\n",
      "        [-7.3361e-03,  1.0699e-02,  6.7066e-03,  ..., -1.3220e-02,\n",
      "         -1.3634e-02, -9.2956e-03],\n",
      "        [-8.2167e-03, -1.4045e-02,  8.8436e-03,  ..., -3.8762e-03,\n",
      "         -1.0058e-02,  1.2668e-02],\n",
      "        ...,\n",
      "        [ 1.3402e-02,  3.8751e-03,  2.1487e-03,  ..., -1.1801e-02,\n",
      "          7.4046e-03, -4.0135e-03],\n",
      "        [ 1.3707e-05,  1.0975e-02, -1.3893e-02,  ..., -1.4384e-02,\n",
      "         -7.4349e-03,  9.3738e-03],\n",
      "        [-9.8444e-03, -5.5194e-03,  3.6027e-03,  ..., -6.0093e-03,\n",
      "         -3.5843e-03, -9.4173e-03]], requires_grad=True)\n",
      "Masked weight\n",
      "tensor([[ 0.0185, -0.0006,  0.0093,  ..., -0.0000, -0.0000, -0.0188],\n",
      "        [-0.0092,  0.0134,  0.0000,  ..., -0.0165, -0.0170, -0.0116],\n",
      "        [-0.0103, -0.0176,  0.0111,  ..., -0.0048, -0.0126,  0.0158],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0027,  ..., -0.0148,  0.0093, -0.0050],\n",
      "        [ 0.0000,  0.0137, -0.0174,  ..., -0.0180, -0.0093,  0.0000],\n",
      "        [-0.0123, -0.0069,  0.0045,  ..., -0.0075, -0.0045, -0.0118]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Output\n",
      "tensor([[ 0.2146,  0.0151,  0.2087,  ...,  0.3066,  0.1170, -0.1244],\n",
      "        [ 0.6754,  0.3925,  0.0610,  ...,  0.2331,  0.2563,  0.2157],\n",
      "        [ 0.3587,  0.3742, -0.1924,  ...,  0.0711, -0.0703,  0.1335],\n",
      "        ...,\n",
      "        [-0.2043, -0.1990,  0.0775,  ..., -0.2292, -0.1511,  0.2432],\n",
      "        [ 0.0962,  0.2980, -0.0803,  ...,  0.3231,  0.2591, -0.0355],\n",
      "        [-0.1245, -0.0327, -0.0238,  ..., -0.0087, -0.0708, -0.3449]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-63-d0c7ccc5ca90>\", line 6, in <module>\n",
      "    train_loss = train(epoch, abs(layer1_dropout))\n",
      "  File \"<ipython-input-61-98dcb0518b03>\", line 12, in train\n",
      "    optimizer.step()\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/torch/optim/sgd.py\", line 107, in step\n",
      "    p.data.add_(-group['lr'], d_p)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2018, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '<ipython-input-63-d0c7ccc5ca90>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/inspect.py\", line 1500, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/inspect.py\", line 1458, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/akash/anaconda3/lib/python3.7/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "init_dropout = 0.2\n",
    "init2_dropout = 0.2\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "                             \n",
    "    train_loss = train(epoch, abs(layer1_dropout))\n",
    "    val_loss = test(epoch)\n",
    "\n",
    "    print(\"Train Loss: \" + str(train_loss))\n",
    "    print(\"Val Loss: \" + str(val_loss))\n",
    "    \n",
    "    diff = val_loss - train_loss\n",
    "\n",
    "    if(val_loss >= train_loss):\n",
    "        \n",
    "        print(\"Previous Loss: \" + str(previous_loss))\n",
    "        \n",
    "        if(diff > previous_loss):\n",
    "            layer1_dropout = layer1_dropout + 0.1\n",
    "            layer2_dropout = layer2_dropout + 0.05\n",
    "            if(layer1_dropout > 0.9):\n",
    "                layer1_dropout = init_dropout\n",
    "                init_dropout = init_dropout + 0.1\n",
    "                if(init_dropout > 0.9):\n",
    "                    init_dropout = 0.2\n",
    "            if(layer2_dropout > 0.9):\n",
    "                layer2_dropout = init2_dropout\n",
    "                init2_dropout = init2_dropout + 0.05\n",
    "                if(init2_dropout > 0.9):\n",
    "                    init_dropout = 0.2\n",
    "\n",
    "    previous_loss = diff\n",
    "    print(\"Diff: \" + str(diff))\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "L4FxFNbjHGVZ",
    "outputId": "4dad3a71-2331-49a5-d0ed-a7b6f4c21aee",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "final_train_counter = []\n",
    "final_train_losses = []\n",
    "final_test_counter = []\n",
    "final_test_losses = []\n",
    "\n",
    "for i in range(0, n_epochs):\n",
    "    final_train_counter.append(i)\n",
    "\n",
    "\"\"\"\n",
    "for i in range(0, len(avg_train_loss)-1, 30):\n",
    "    index = int(i/10)\n",
    "    final_train_counter.append(train_counter[i])\n",
    "    final_train_losses.append((train_losses[i] + train_losses[i+1]) / 2)\n",
    "    final_test_counter.append(train_counter[i])\n",
    "    final_test_losses.append((test_losses[i] + test_losses[i+1]) / 2)\n",
    "\n",
    "final_train_counter.append(train_counter[len(train_counter)-1]) \n",
    "final_train_losses.append(train_losses[len(train_counter)-1])\n",
    "final_test_counter.append(train_counter[len(train_counter)-1])\n",
    "final_test_losses.append(test_losses[len(train_counter)-1])    \n",
    "    \n",
    "plt.plot(len(avg_train_loss), avg_train_loss, color='blue')\n",
    "plt.scatter(avg_train_loss[-1], avg_train_loss[-1], color='blue')\n",
    "plt.plot(len(avg_test_losses), avg_test_losses, color='red')\n",
    "plt.scatter(avg_test_losses[-1], avg_test_losses[-1], color='red')\n",
    "\n",
    "# print(len(test_counter))\n",
    "# print(len(test_losses))\n",
    "\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')\n",
    "\"\"\"\n",
    "\n",
    "plt.plot(final_train_counter, avg_train_loss, color='blue')\n",
    "plt.scatter(final_train_counter[-1], avg_train_loss[-1], color='blue')\n",
    "plt.plot(final_train_counter, avg_test_loss, color='red')\n",
    "plt.scatter(final_train_counter[-1], avg_test_loss[-1], color='red')\n",
    "# plt.plot(final_train_counter, test_accuracy_list, color='orange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "w0u5NUsFj-mt",
    "outputId": "e1f7b611-c84f-4ff4-eb98-c24c6ec78e29"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "\n",
    "last_acc = []\n",
    "last_counter = []\n",
    "index = 0\n",
    "for acc in range(0, len(test_accuracy_list)) :\n",
    "    last_acc.append(test_accuracy_list[acc])\n",
    "    last_counter.append(final_train_counter[index])\n",
    "    index = index + 1\n",
    "\n",
    "plt.plot(last_counter, last_acc, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "2FCsH3Q9aq0T",
    "outputId": "fa051d13-d29c-48b1-941a-4b39d59672e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-66d6fa5c3cd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0macc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mnist64_adaptive_tabu_acc.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0macc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotter'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotter\n",
    "\n",
    "acc1 = plotter.SavedAccuracy(name='mnist64_adaptive_tabu_acc.pkl')\n",
    "acc1.saveGraph(last_acc, last_counter)\n",
    "#a, c = acc1.loadGraph()\n",
    "#plt.plot(c, a, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqS_VMKOaq0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJa35oEyHGVf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "for i in range(0, 10):\n",
    "    batch_idx, (example_data, example_targets) = next(examples)\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        output = network(example_data)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        for i in range(6):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "            plt.title(\"Prediction: {}\".format(\n",
    "                output.data.max(1, keepdim=True)[1][i].item()))\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Adlhca7pHGVo"
   },
   "outputs": [],
   "source": [
    "# Reloading a already saved model\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "continued_network = Net()\n",
    "continued_optimizer = optim.SGD(continued_network.parameters(), lr=learning_rate,\n",
    "                                momentum=momentum)\n",
    "\n",
    "network_state_dict = torch.load('./results/model.pth')\n",
    "continued_network.load_state_dict(network_state_dict)\n",
    "\n",
    "optimizer_state_dict = torch.load('./results/optimizer.pth')\n",
    "continued_optimizer.load_state_dict(optimizer_state_dict)\n",
    "\n",
    "examples = enumerate(test_loader)\n",
    "for i in range(0, 2):\n",
    "    batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = continued_network(example_data)\n",
    "\n",
    "        fig = plt.figure()\n",
    "        for i in range(6):\n",
    "            plt.subplot(2,3,i+1)\n",
    "            plt.tight_layout()\n",
    "            plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "            plt.title(\"Prediction: {}\".format(\n",
    "                output.data.max(1, keepdim=True)[1][i].item()))\n",
    "            \n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLlTgHruHGVt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AANN Dropout.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
